[
  {
    "name": "config",
    "version": "biome",
    "framework": "shared",
    "type": "snippet",
    "files": []
  },
  {
    "name": "express",
    "version": "eslint",
    "framework": "shared",
    "type": "snippet",
    "files": []
  },
  {
    "name": "config",
    "version": "prettier",
    "framework": "shared",
    "type": "snippet",
    "files": []
  },
  {
    "name": "express",
    "version": "tsconfig",
    "framework": "shared",
    "type": "snippet",
    "files": []
  },
  {
    "name": "drizzle-client",
    "description": "Drizzle ORM client setup with PostgreSQL",
    "dependencies": [
      "drizzle-orm",
      "pg"
    ],
    "devDependencies": [
      "drizzle-kit",
      "@types/pg"
    ],
    "files": [
      {
        "name": "libs/db/drizzle.ts",
        "path": "libs/db/drizzle.ts",
        "content": "import { drizzle } from 'drizzle-orm/node-postgres';\nimport { Pool } from 'pg';\n\n/**\n * PostgreSQL connection pool\n */\nconst pool = new Pool({\n  connectionString: process.env.DATABASE_URL,\n  max: 20,                    // Maximum connections in pool\n  idleTimeoutMillis: 30000,   // Close idle connections after 30s\n  connectionTimeoutMillis: 5000,\n});\n\n// Log pool errors\npool.on('error', (err) => {\n  console.error('[ERROR] Unexpected database pool error:', err);\n});\n\n/**\n * Drizzle ORM instance\n * Import your schema and pass it here for type-safe queries\n * \n * @example\n * import * as schema from './schema';\n * export const db = drizzle(pool, { schema });\n */\nexport const db = drizzle(pool);\n\n/**\n * Connect to database with health check\n */\nexport const connectDatabase = async () => {\n  try {\n    const client = await pool.connect();\n    await client.query('SELECT NOW()');\n    client.release();\n    console.log('[OK] Database connected');\n  } catch (error) {\n    console.error('[ERROR] Database connection failed:', error);\n    throw error;\n  }\n};\n\n/**\n * Disconnect from database (for graceful shutdown)\n */\nexport const disconnectDatabase = async () => {\n  await pool.end();\n  console.log('[INFO] Database disconnected');\n};\n\n/**\n * Health check for database connection\n */\nexport const isDatabaseHealthy = async (): Promise<boolean> => {\n  try {\n    const client = await pool.connect();\n    await client.query('SELECT 1');\n    client.release();\n    return true;\n  } catch {\n    return false;\n  }\n};\n\n/**\n * Transaction helper\n * @example\n * await transaction(async (tx) => {\n *   await tx.insert(users).values({ name: 'John' });\n *   await tx.insert(posts).values({ title: 'Hello' });\n * });\n */\nexport const transaction = async <T>(\n  fn: (tx: typeof db) => Promise<T>\n): Promise<T> => {\n  return db.transaction(fn);\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "db",
    "type": "snippet"
  },
  {
    "name": "mongoose-client",
    "description": "Mongoose ODM client setup with connection handling and example model",
    "dependencies": [
      "mongoose"
    ],
    "files": [
      {
        "name": "libs/db/mongoose.ts",
        "path": "libs/db/mongoose.ts",
        "content": "import mongoose from 'mongoose';\n\n/**\n * Mongoose connection options\n */\nconst options: mongoose.ConnectOptions = {\n  maxPoolSize: 20,\n  minPoolSize: 5,\n  serverSelectionTimeoutMS: 5000,\n  socketTimeoutMS: 45000,\n};\n\n/**\n * Connect to MongoDB with retry logic\n */\nexport const connectDatabase = async (retries = 5, delay = 5000): Promise<void> => {\n  const uri = process.env.MONGODB_URI || 'mongodb://localhost:27017/database';\n  \n  for (let i = 0; i < retries; i++) {\n    try {\n      await mongoose.connect(uri, options);\n      console.log('[OK] MongoDB connected');\n      return;\n    } catch (error) {\n      console.error(`[ERROR] MongoDB connection failed (attempt ${i + 1}/${retries})`);\n      if (i < retries - 1) {\n        await new Promise((r) => setTimeout(r, delay));\n      }\n    }\n  }\n  throw new Error('Failed to connect to MongoDB after retries');\n};\n\n/**\n * Disconnect from database (for graceful shutdown)\n */\nexport const disconnectDatabase = async (): Promise<void> => {\n  await mongoose.disconnect();\n  console.log('[INFO] MongoDB disconnected');\n};\n\n/**\n * Health check for database connection\n */\nexport const isDatabaseHealthy = async (): Promise<boolean> => {\n  try {\n    if (mongoose.connection.readyState !== 1) return false;\n    await mongoose.connection.db?.admin().ping();\n    return true;\n  } catch {\n    return false;\n  }\n};\n\n/**\n * Connection event handlers\n */\nmongoose.connection.on('error', (err) => {\n  console.error('[ERROR] MongoDB connection error:', err);\n});\n\nmongoose.connection.on('disconnected', () => {\n  console.log('[INFO] MongoDB disconnected');\n});\n\nmongoose.connection.on('reconnected', () => {\n  console.log('[OK] MongoDB reconnected');\n});\n\n// ============================================\n// Example User Model - Modify as needed\n// ============================================\n\nexport interface IUser {\n  email: string;\n  name?: string;\n  isDeleted?: boolean;\n  createdAt?: Date;\n  updatedAt?: Date;\n}\n\nconst userSchema = new mongoose.Schema<IUser>(\n  {\n    email: { type: String, required: true, unique: true },\n    name: { type: String },\n    isDeleted: { type: Boolean, default: false }, // soft delete\n  },\n  {\n    timestamps: true, // auto createdAt & updatedAt\n    collection: 'users',\n  }\n);\n\n// Exclude soft-deleted documents by default\nuserSchema.pre('find', function () {\n  this.where({ isDeleted: { $ne: true } });\n});\n\nuserSchema.pre('findOne', function () {\n  this.where({ isDeleted: { $ne: true } });\n});\n\nexport const User = mongoose.model<IUser>('User', userSchema);\n\n// Export mongoose for advanced usage\nexport { mongoose };\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "db",
    "type": "snippet"
  },
  {
    "name": "prisma-client",
    "description": "Prisma ORM client setup with logging and connection handling",
    "dependencies": [
      "@prisma/client"
    ],
    "devDependencies": [
      "prisma"
    ],
    "files": [
      {
        "name": "libs/db/prisma.ts",
        "path": "libs/db/prisma.ts",
        "content": "import { PrismaClient } from '@prisma/client';\n\n/**\n * Prisma client configuration\n * Logs queries in development, only errors in production\n */\nconst prismaClientSingleton = () => {\n  return new PrismaClient({\n    log:\n      process.env.NODE_ENV === 'development'\n        ? ['query', 'info', 'warn', 'error']\n        : ['error'],\n    errorFormat: 'pretty',\n  });\n};\n\n// Prevent multiple instances in development (hot reloading)\ndeclare global {\n  var prisma: undefined | ReturnType<typeof prismaClientSingleton>;\n}\n\nexport const prisma = globalThis.prisma ?? prismaClientSingleton();\n\nif (process.env.NODE_ENV !== 'production') {\n  globalThis.prisma = prisma;\n}\n\n/**\n * Connect to database with retry logic\n */\nexport const connectDatabase = async (retries = 5, delay = 5000) => {\n  for (let i = 0; i < retries; i++) {\n    try {\n      await prisma.$connect();\n      console.log('[OK] Database connected');\n      return;\n    } catch (error) {\n      console.error(`[ERROR] Database connection failed (attempt ${i + 1}/${retries})`);\n      if (i < retries - 1) {\n        await new Promise((r) => setTimeout(r, delay));\n      }\n    }\n  }\n  throw new Error('Failed to connect to database after retries');\n};\n\n/**\n * Disconnect from database (for graceful shutdown)\n */\nexport const disconnectDatabase = async () => {\n  await prisma.$disconnect();\n  console.log('[INFO] Database disconnected');\n};\n\n/**\n * Health check for database connection\n */\nexport const isDatabaseHealthy = async (): Promise<boolean> => {\n  try {\n    await prisma.$queryRaw`SELECT 1`;\n    return true;\n  } catch {\n    return false;\n  }\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "db",
    "type": "snippet"
  },
  {
    "name": "redis-client",
    "description": "Redis client setup with connection handling and retry logic",
    "dependencies": [
      "ioredis"
    ],
    "devDependencies": [
      "@types/ioredis"
    ],
    "files": [
      {
        "name": "libs/db/redis.ts",
        "path": "libs/db/redis.ts",
        "content": "import Redis from 'ioredis';\n\n/**\n * Redis client configuration\n */\nconst redisConfig = {\n  host: process.env.REDIS_HOST || 'localhost',\n  port: parseInt(process.env.REDIS_PORT || '6379', 10),\n  password: process.env.REDIS_PASSWORD || undefined,\n  db: parseInt(process.env.REDIS_DB || '0', 10),\n  retryStrategy: (times: number) => {\n    if (times > 10) {\n      console.error('[ERROR] Redis: Max retries reached');\n      return null; // Stop retrying\n    }\n    return Math.min(times * 100, 3000); // Exponential backoff, max 3s\n  },\n  maxRetriesPerRequest: 3,\n};\n\n/**\n * Redis client instance\n */\nexport const redis = new Redis(redisConfig);\n\n// Connection event handlers\nredis.on('connect', () => {\n  console.log('[OK] Redis connected');\n});\n\nredis.on('error', (err) => {\n  console.error('[ERROR] Redis error:', err.message);\n});\n\nredis.on('close', () => {\n  console.log('[INFO] Redis connection closed');\n});\n\n/**\n * Disconnect from Redis (for graceful shutdown)\n */\nexport const disconnectRedis = async () => {\n  await redis.quit();\n};\n\n/**\n * Health check for Redis connection\n */\nexport const isRedisHealthy = async (): Promise<boolean> => {\n  try {\n    const pong = await redis.ping();\n    return pong === 'PONG';\n  } catch {\n    return false;\n  }\n};\n\n/**\n * Cache helpers with JSON serialization\n */\nexport const cache = {\n  /**\n   * Get cached value\n   */\n  async get<T>(key: string): Promise<T | null> {\n    const value = await redis.get(key);\n    if (!value) return null;\n    try {\n      return JSON.parse(value) as T;\n    } catch {\n      return value as T;\n    }\n  },\n\n  /**\n   * Set cached value with optional TTL\n   * @param key Cache key\n   * @param value Value to cache\n   * @param ttlSeconds Time to live in seconds (optional)\n   */\n  async set(key: string, value: unknown, ttlSeconds?: number): Promise<void> {\n    const serialized = typeof value === 'string' ? value : JSON.stringify(value);\n    if (ttlSeconds) {\n      await redis.setex(key, ttlSeconds, serialized);\n    } else {\n      await redis.set(key, serialized);\n    }\n  },\n\n  /**\n   * Delete cached value\n   */\n  async del(key: string): Promise<void> {\n    await redis.del(key);\n  },\n\n  /**\n   * Check if key exists\n   */\n  async exists(key: string): Promise<boolean> {\n    return (await redis.exists(key)) === 1;\n  },\n\n  /**\n   * Get remaining TTL in seconds\n   */\n  async ttl(key: string): Promise<number> {\n    return redis.ttl(key);\n  },\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "db",
    "type": "snippet"
  },
  {
    "name": "env-validation",
    "description": "Type-safe environment variable validation using Zod",
    "dependencies": [
      "zod",
      "dotenv"
    ],
    "files": [
      {
        "name": "config/env.ts",
        "path": "config/env.ts",
        "content": "import 'dotenv/config';\nimport { z } from 'zod';\n\nconst envSchema = z.object({\n  NODE_ENV: z.enum(['development', 'production', 'test']).default('development'),\n  PORT: z.string().transform(Number).default('3000'),\n  // Add your environment variables here\n  // DATABASE_URL: z.string().url(),\n  // JWT_SECRET: z.string().min(1),\n});\n\nconst _env = envSchema.safeParse(process.env);\n\nif (!_env.success) {\n  console.error('[ERROR] Invalid environment variables:');\n  _env.error.format()._errors.forEach((message) => {\n    console.error(message);\n  });\n  // Flatten errors for better readability\n  Object.entries(_env.error.flatten().fieldErrors).forEach(([key, errors]) => {\n      console.error(`  ${key}: ${errors.join(', ')}`);\n  });\n  \n  process.exit(1);\n}\n\nexport const env = _env.data;\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "libs",
    "type": "snippet"
  },
  {
    "name": "http-client",
    "description": "HTTP client wrapper with retry, timeout, and error handling",
    "dependencies": [
      "axios"
    ],
    "files": [
      {
        "name": "libs/http-client.ts",
        "path": "libs/http-client.ts",
        "content": "import axios, { AxiosInstance, AxiosRequestConfig, AxiosError } from 'axios';\n\n/**\n * HTTP client configuration\n */\ninterface HttpClientConfig {\n  baseURL?: string;\n  timeout?: number;\n  retries?: number;\n  retryDelay?: number;\n  headers?: Record<string, string>;\n}\n\n/**\n * Create a configured HTTP client instance\n */\nexport const createHttpClient = (config: HttpClientConfig = {}): AxiosInstance => {\n  const {\n    baseURL,\n    timeout = 10000,\n    retries = 3,\n    retryDelay = 1000,\n    headers = {},\n  } = config;\n\n  const client = axios.create({\n    baseURL,\n    timeout,\n    headers: {\n      'Content-Type': 'application/json',\n      ...headers,\n    },\n  });\n\n  // Request interceptor\n  client.interceptors.request.use(\n    (config) => {\n      // Add timestamp for debugging\n      (config as any).metadata = { startTime: Date.now() };\n      return config;\n    },\n    (error) => Promise.reject(error)\n  );\n\n  // Response interceptor with retry logic\n  client.interceptors.response.use(\n    (response) => {\n      // Calculate request duration\n      const duration = Date.now() - (response.config as any).metadata?.startTime;\n      console.log(`[OK] ${response.config.method?.toUpperCase()} ${response.config.url} - ${response.status} (${duration}ms)`);\n      return response;\n    },\n    async (error: AxiosError) => {\n      const config = error.config as AxiosRequestConfig & { _retryCount?: number };\n      \n      if (!config) {\n        return Promise.reject(error);\n      }\n\n      config._retryCount = config._retryCount || 0;\n\n      // Retry on network errors or 5xx errors\n      const shouldRetry =\n        (error.code === 'ECONNABORTED' || // Timeout\n         error.code === 'ENOTFOUND' ||    // DNS\n         error.code === 'ECONNRESET' ||   // Connection reset\n         (error.response && error.response.status >= 500)) &&\n        config._retryCount < retries;\n\n      if (shouldRetry) {\n        config._retryCount++;\n        console.warn(`[WARN] Retrying request (${config._retryCount}/${retries}): ${config.url}`);\n        \n        // Exponential backoff\n        await new Promise((r) => setTimeout(r, retryDelay * config._retryCount!));\n        \n        return client(config);\n      }\n\n      // Log error\n      console.error(`[ERROR] ${config.method?.toUpperCase()} ${config.url} - ${error.response?.status || error.code}`);\n      \n      return Promise.reject(error);\n    }\n  );\n\n  return client;\n};\n\n/**\n * Default HTTP client instance\n */\nexport const httpClient = createHttpClient();\n\n/**\n * Type-safe request helpers\n */\nexport const http = {\n  get: <T>(url: string, config?: AxiosRequestConfig) =>\n    httpClient.get<T>(url, config).then((r) => r.data),\n\n  post: <T>(url: string, data?: unknown, config?: AxiosRequestConfig) =>\n    httpClient.post<T>(url, data, config).then((r) => r.data),\n\n  put: <T>(url: string, data?: unknown, config?: AxiosRequestConfig) =>\n    httpClient.put<T>(url, data, config).then((r) => r.data),\n\n  patch: <T>(url: string, data?: unknown, config?: AxiosRequestConfig) =>\n    httpClient.patch<T>(url, data, config).then((r) => r.data),\n\n  delete: <T>(url: string, config?: AxiosRequestConfig) =>\n    httpClient.delete<T>(url, config).then((r) => r.data),\n};\n\n/**\n * Error handling utility\n */\nexport const isHttpError = (error: unknown): error is AxiosError => {\n  return axios.isAxiosError(error);\n};\n\nexport const getErrorMessage = (error: unknown): string => {\n  if (isHttpError(error)) {\n    return (\n      (error.response?.data as any)?.message ||\n      error.message ||\n      'An error occurred'\n    );\n  }\n  return error instanceof Error ? error.message : 'Unknown error';\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "libs",
    "type": "snippet"
  },
  {
    "name": "aws-ses",
    "description": "Email sending utility using AWS SES",
    "dependencies": [
      "@aws-sdk/client-ses"
    ],
    "files": [
      {
        "name": "libs/mailers/aws-ses.ts",
        "path": "libs/mailers/aws-ses.ts",
        "content": "import {\n  SESClient,\n  SendEmailCommand,\n  SendRawEmailCommand,\n  SendBulkTemplatedEmailCommand,\n} from '@aws-sdk/client-ses';\n\n/**\n * SES client configuration\n */\nconst sesClient = new SESClient({\n  region: process.env.AWS_REGION || 'us-east-1',\n  credentials: process.env.AWS_ACCESS_KEY_ID\n    ? {\n        accessKeyId: process.env.AWS_ACCESS_KEY_ID,\n        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || '',\n      }\n    : undefined, // Use IAM role if no credentials\n});\n\nconst FROM_EMAIL = process.env.SES_FROM_EMAIL || 'noreply@example.com';\n\n/**\n * Email options interface\n */\ninterface SendEmailOptions {\n  to: string | string[];\n  subject: string;\n  text?: string;\n  html?: string;\n  from?: string;\n  replyTo?: string[];\n  cc?: string[];\n  bcc?: string[];\n}\n\n/**\n * Send an email using AWS SES\n */\nexport const sendMail = async (options: SendEmailOptions) => {\n  const toAddresses = Array.isArray(options.to) ? options.to : [options.to];\n\n  const command = new SendEmailCommand({\n    Source: options.from || FROM_EMAIL,\n    Destination: {\n      ToAddresses: toAddresses,\n      CcAddresses: options.cc,\n      BccAddresses: options.bcc,\n    },\n    Message: {\n      Subject: {\n        Data: options.subject,\n        Charset: 'UTF-8',\n      },\n      Body: {\n        ...(options.text && {\n          Text: {\n            Data: options.text,\n            Charset: 'UTF-8',\n          },\n        }),\n        ...(options.html && {\n          Html: {\n            Data: options.html,\n            Charset: 'UTF-8',\n          },\n        }),\n      },\n    },\n    ReplyToAddresses: options.replyTo,\n  });\n\n  try {\n    const response = await sesClient.send(command);\n    console.log(`[EMAIL] Email sent: ${response.MessageId}`);\n    return response;\n  } catch (error) {\n    console.error('[ERROR] SES error:', error);\n    throw error;\n  }\n};\n\n/**\n * Send using SES template\n * Requires a pre-configured SES template\n */\nexport const sendWithTemplate = async (\n  to: string | string[],\n  templateName: string,\n  templateData: Record<string, unknown>,\n  options?: Partial<SendEmailOptions>\n) => {\n  const { SendTemplatedEmailCommand } = await import('@aws-sdk/client-ses');\n\n  const command = new SendTemplatedEmailCommand({\n    Source: options?.from || FROM_EMAIL,\n    Destination: {\n      ToAddresses: Array.isArray(to) ? to : [to],\n    },\n    Template: templateName,\n    TemplateData: JSON.stringify(templateData),\n    ReplyToAddresses: options?.replyTo,\n  });\n\n  try {\n    const response = await sesClient.send(command);\n    console.log(`[EMAIL] Template email sent: ${response.MessageId}`);\n    return response;\n  } catch (error) {\n    console.error('[ERROR] SES template error:', error);\n    throw error;\n  }\n};\n\n/**\n * Send bulk emails (up to 50 destinations per request)\n */\nexport const sendBulkEmails = async (\n  emails: Array<{\n    to: string;\n    templateData: Record<string, unknown>;\n  }>,\n  templateName: string,\n  from?: string\n) => {\n  const command = new SendBulkTemplatedEmailCommand({\n    Source: from || FROM_EMAIL,\n    Template: templateName,\n    DefaultTemplateData: JSON.stringify({}),\n    Destinations: emails.map((email) => ({\n      Destination: {\n        ToAddresses: [email.to],\n      },\n      ReplacementTemplateData: JSON.stringify(email.templateData),\n    })),\n  });\n\n  try {\n    const response = await sesClient.send(command);\n    console.log(`[EMAIL] Bulk sent: ${emails.length} emails`);\n    return response;\n  } catch (error) {\n    console.error('[ERROR] SES bulk error:', error);\n    throw error;\n  }\n};\n\n/**\n * Common email templates\n */\nexport const templates = {\n  passwordReset: (resetUrl: string, expiresIn = '1 hour') => ({\n    subject: 'Reset Your Password',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Password Reset Request</h2>\n        <p>You requested to reset your password. Click the button below to proceed:</p>\n        <a href=\"${resetUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #007bff; color: white; text-decoration: none; border-radius: 4px;\">\n          Reset Password\n        </a>\n        <p style=\"margin-top: 20px; color: #666;\">\n          This link expires in ${expiresIn}. If you didn't request this, please ignore this email.\n        </p>\n      </div>\n    `,\n  }),\n\n  welcome: (name: string, loginUrl: string) => ({\n    subject: 'Welcome!',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Welcome, ${name}!</h2>\n        <p>Thanks for signing up. We're excited to have you on board.</p>\n        <a href=\"${loginUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #28a745; color: white; text-decoration: none; border-radius: 4px;\">\n          Get Started\n        </a>\n      </div>\n    `,\n  }),\n\n  verifyEmail: (verifyUrl: string) => ({\n    subject: 'Verify Your Email',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Verify Your Email</h2>\n        <p>Please verify your email address by clicking the button below:</p>\n        <a href=\"${verifyUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #007bff; color: white; text-decoration: none; border-radius: 4px;\">\n          Verify Email\n        </a>\n      </div>\n    `,\n  }),\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "mailers",
    "type": "snippet"
  },
  {
    "name": "mailer",
    "description": "Email sending utility using Nodemailer with templates support",
    "dependencies": [
      "nodemailer"
    ],
    "devDependencies": [
      "@types/nodemailer"
    ],
    "files": [
      {
        "name": "libs/mailer.ts",
        "path": "libs/mailer.ts",
        "content": "import nodemailer, { Transporter } from 'nodemailer';\n\n/**\n * Email configuration from environment variables\n */\nconst config = {\n  host: process.env.SMTP_HOST || 'smtp.gmail.com',\n  port: parseInt(process.env.SMTP_PORT || '587', 10),\n  secure: process.env.SMTP_SECURE === 'true',\n  auth: {\n    user: process.env.SMTP_USER,\n    pass: process.env.SMTP_PASS,\n  },\n  from: process.env.SMTP_FROM || 'noreply@example.com',\n};\n\n/**\n * Nodemailer transporter instance\n */\nlet transporter: Transporter | null = null;\n\n/**\n * Initialize mail transporter\n */\nexport const initMailer = () => {\n  if (!config.auth.user || !config.auth.pass) {\n    console.warn('[WARN] SMTP credentials not configured, email disabled');\n    return;\n  }\n\n  transporter = nodemailer.createTransport({\n    host: config.host,\n    port: config.port,\n    secure: config.secure,\n    auth: config.auth,\n  });\n\n  console.log('[OK] Mailer initialized');\n};\n\n/**\n * Verify SMTP connection\n */\nexport const verifyMailer = async (): Promise<boolean> => {\n  if (!transporter) return false;\n  \n  try {\n    await transporter.verify();\n    return true;\n  } catch (error) {\n    console.error('[ERROR] SMTP verification failed:', error);\n    return false;\n  }\n};\n\n/**\n * Email options interface\n */\ninterface SendMailOptions {\n  to: string | string[];\n  subject: string;\n  text?: string;\n  html?: string;\n  from?: string;\n  replyTo?: string;\n  attachments?: Array<{\n    filename: string;\n    content?: string | Buffer;\n    path?: string;\n  }>;\n}\n\n/**\n * Send an email\n */\nexport const sendMail = async (options: SendMailOptions) => {\n  if (!transporter) {\n    throw new Error('Mailer not initialized. Call initMailer() first.');\n  }\n\n  const mailOptions = {\n    from: options.from || config.from,\n    to: Array.isArray(options.to) ? options.to.join(', ') : options.to,\n    subject: options.subject,\n    text: options.text,\n    html: options.html,\n    replyTo: options.replyTo,\n    attachments: options.attachments,\n  };\n\n  try {\n    const info = await transporter.sendMail(mailOptions);\n    console.log(`[EMAIL] Email sent: ${info.messageId}`);\n    return info;\n  } catch (error) {\n    console.error('[ERROR] Failed to send email:', error);\n    throw error;\n  }\n};\n\n/**\n * Common email templates\n */\nexport const templates = {\n  /**\n   * Password reset email\n   */\n  passwordReset: (resetUrl: string, expiresIn = '1 hour') => ({\n    subject: 'Reset Your Password',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Password Reset Request</h2>\n        <p>You requested to reset your password. Click the button below to proceed:</p>\n        <a href=\"${resetUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #007bff; color: white; text-decoration: none; border-radius: 4px;\">\n          Reset Password\n        </a>\n        <p style=\"margin-top: 20px; color: #666;\">\n          This link expires in ${expiresIn}. If you didn't request this, please ignore this email.\n        </p>\n      </div>\n    `,\n    text: `Reset your password: ${resetUrl}\\n\\nThis link expires in ${expiresIn}.`,\n  }),\n\n  /**\n   * Welcome email\n   */\n  welcome: (name: string, loginUrl: string) => ({\n    subject: 'Welcome!',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Welcome, ${name}!</h2>\n        <p>Thanks for signing up. We're excited to have you on board.</p>\n        <a href=\"${loginUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #28a745; color: white; text-decoration: none; border-radius: 4px;\">\n          Get Started\n        </a>\n      </div>\n    `,\n    text: `Welcome, ${name}!\\n\\nGet started: ${loginUrl}`,\n  }),\n\n  /**\n   * Email verification\n   */\n  verifyEmail: (verifyUrl: string) => ({\n    subject: 'Verify Your Email',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Verify Your Email</h2>\n        <p>Please verify your email address by clicking the button below:</p>\n        <a href=\"${verifyUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #007bff; color: white; text-decoration: none; border-radius: 4px;\">\n          Verify Email\n        </a>\n      </div>\n    `,\n    text: `Verify your email: ${verifyUrl}`,\n  }),\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "mailers",
    "type": "snippet"
  },
  {
    "name": "resend",
    "description": "Email sending utility using Resend API",
    "dependencies": [
      "resend"
    ],
    "files": [
      {
        "name": "libs/mailers/resend.ts",
        "path": "libs/mailers/resend.ts",
        "content": "import { Resend } from 'resend';\n\n/**\n * Resend client configuration\n */\nconst resend = new Resend(process.env.RESEND_API_KEY);\n\nconst FROM_EMAIL = process.env.RESEND_FROM_EMAIL || 'onboarding@resend.dev';\n\n/**\n * Email options interface\n */\ninterface SendEmailOptions {\n  to: string | string[];\n  subject: string;\n  text?: string;\n  html?: string;\n  from?: string;\n  replyTo?: string;\n  cc?: string | string[];\n  bcc?: string | string[];\n  attachments?: Array<{\n    filename: string;\n    content: Buffer | string;\n  }>;\n}\n\n/**\n * Send an email using Resend\n */\nexport const sendMail = async (options: SendEmailOptions) => {\n  if (!process.env.RESEND_API_KEY) {\n    throw new Error('RESEND_API_KEY environment variable is not set');\n  }\n\n  try {\n    const { data, error } = await resend.emails.send({\n      from: options.from || FROM_EMAIL,\n      to: Array.isArray(options.to) ? options.to : [options.to],\n      subject: options.subject,\n      text: options.text,\n      html: options.html,\n      reply_to: options.replyTo,\n      cc: options.cc ? (Array.isArray(options.cc) ? options.cc : [options.cc]) : undefined,\n      bcc: options.bcc ? (Array.isArray(options.bcc) ? options.bcc : [options.bcc]) : undefined,\n      attachments: options.attachments,\n    });\n\n    if (error) {\n      console.error('[ERROR] Resend error:', error);\n      throw new Error(error.message);\n    }\n\n    console.log(`[EMAIL] Email sent: ${data?.id}`);\n    return data;\n  } catch (error) {\n    console.error('[ERROR] Failed to send email:', error);\n    throw error;\n  }\n};\n\n/**\n * Send batch emails (up to 100 emails per request)\n */\nexport const sendBatchEmails = async (\n  emails: Array<Omit<SendEmailOptions, 'from'> & { from?: string }>\n) => {\n  const batch = emails.map((email) => ({\n    from: email.from || FROM_EMAIL,\n    to: Array.isArray(email.to) ? email.to : [email.to],\n    subject: email.subject,\n    text: email.text,\n    html: email.html,\n  }));\n\n  const { data, error } = await resend.batch.send(batch);\n\n  if (error) {\n    console.error('[ERROR] Batch send error:', error);\n    throw new Error(error.message);\n  }\n\n  return data;\n};\n\n/**\n * Common email templates\n */\nexport const templates = {\n  passwordReset: (resetUrl: string, expiresIn = '1 hour') => ({\n    subject: 'Reset Your Password',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Password Reset Request</h2>\n        <p>You requested to reset your password. Click the button below to proceed:</p>\n        <a href=\"${resetUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #007bff; color: white; text-decoration: none; border-radius: 4px;\">\n          Reset Password\n        </a>\n        <p style=\"margin-top: 20px; color: #666;\">\n          This link expires in ${expiresIn}. If you didn't request this, please ignore this email.\n        </p>\n      </div>\n    `,\n  }),\n\n  welcome: (name: string, loginUrl: string) => ({\n    subject: 'Welcome!',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Welcome, ${name}!</h2>\n        <p>Thanks for signing up. We're excited to have you on board.</p>\n        <a href=\"${loginUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #28a745; color: white; text-decoration: none; border-radius: 4px;\">\n          Get Started\n        </a>\n      </div>\n    `,\n  }),\n\n  verifyEmail: (verifyUrl: string) => ({\n    subject: 'Verify Your Email',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Verify Your Email</h2>\n        <p>Please verify your email address by clicking the button below:</p>\n        <a href=\"${verifyUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #007bff; color: white; text-decoration: none; border-radius: 4px;\">\n          Verify Email\n        </a>\n      </div>\n    `,\n  }),\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "mailers",
    "type": "snippet"
  },
  {
    "name": "sendgrid",
    "description": "Email sending utility using SendGrid API",
    "dependencies": [
      "@sendgrid/mail"
    ],
    "files": [
      {
        "name": "libs/mailers/sendgrid.ts",
        "path": "libs/mailers/sendgrid.ts",
        "content": "import sgMail from '@sendgrid/mail';\n\n/**\n * Initialize SendGrid with API key\n */\nif (process.env.SENDGRID_API_KEY) {\n  sgMail.setApiKey(process.env.SENDGRID_API_KEY);\n}\n\nconst FROM_EMAIL = process.env.SENDGRID_FROM_EMAIL || 'noreply@example.com';\n\n/**\n * Email options interface\n */\ninterface SendEmailOptions {\n  to: string | string[];\n  subject: string;\n  text?: string;\n  html?: string;\n  from?: string;\n  replyTo?: string;\n  cc?: string | string[];\n  bcc?: string | string[];\n  attachments?: Array<{\n    filename: string;\n    content: string; // Base64 encoded\n    type?: string;\n    disposition?: 'attachment' | 'inline';\n  }>;\n  templateId?: string;\n  dynamicTemplateData?: Record<string, unknown>;\n}\n\n/**\n * Send an email using SendGrid\n */\nexport const sendMail = async (options: SendEmailOptions) => {\n  if (!process.env.SENDGRID_API_KEY) {\n    throw new Error('SENDGRID_API_KEY environment variable is not set');\n  }\n\n  try {\n    const msg: sgMail.MailDataRequired = {\n      to: options.to,\n      from: options.from || FROM_EMAIL,\n      subject: options.subject,\n      text: options.text,\n      html: options.html,\n      replyTo: options.replyTo,\n      cc: options.cc,\n      bcc: options.bcc,\n      attachments: options.attachments,\n      templateId: options.templateId,\n      dynamicTemplateData: options.dynamicTemplateData,\n    };\n\n    const [response] = await sgMail.send(msg);\n    console.log(`[EMAIL] Email sent: ${response.headers['x-message-id']}`);\n    return response;\n  } catch (error: any) {\n    console.error('[ERROR] SendGrid error:', error.response?.body || error.message);\n    throw error;\n  }\n};\n\n/**\n * Send batch emails (up to 1000 recipients per request)\n */\nexport const sendBatchEmails = async (\n  emails: Array<Omit<SendEmailOptions, 'from'> & { from?: string }>\n) => {\n  const messages = emails.map((email) => ({\n    to: email.to,\n    from: email.from || FROM_EMAIL,\n    subject: email.subject,\n    text: email.text,\n    html: email.html,\n    templateId: email.templateId,\n    dynamicTemplateData: email.dynamicTemplateData,\n  }));\n\n  try {\n    const responses = await sgMail.send(messages);\n    console.log(`[EMAIL] Batch sent: ${messages.length} emails`);\n    return responses;\n  } catch (error: any) {\n    console.error('[ERROR] Batch send error:', error.response?.body || error.message);\n    throw error;\n  }\n};\n\n/**\n * Send using SendGrid dynamic template\n */\nexport const sendWithTemplate = async (\n  to: string | string[],\n  templateId: string,\n  dynamicData: Record<string, unknown>,\n  options?: Partial<SendEmailOptions>\n) => {\n  return sendMail({\n    to,\n    subject: '', // Subject comes from template\n    templateId,\n    dynamicTemplateData: dynamicData,\n    ...options,\n  });\n};\n\n/**\n * Common email templates (for inline HTML, not SendGrid templates)\n */\nexport const templates = {\n  passwordReset: (resetUrl: string, expiresIn = '1 hour') => ({\n    subject: 'Reset Your Password',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Password Reset Request</h2>\n        <p>You requested to reset your password. Click the button below to proceed:</p>\n        <a href=\"${resetUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #007bff; color: white; text-decoration: none; border-radius: 4px;\">\n          Reset Password\n        </a>\n        <p style=\"margin-top: 20px; color: #666;\">\n          This link expires in ${expiresIn}. If you didn't request this, please ignore this email.\n        </p>\n      </div>\n    `,\n  }),\n\n  welcome: (name: string, loginUrl: string) => ({\n    subject: 'Welcome!',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Welcome, ${name}!</h2>\n        <p>Thanks for signing up. We're excited to have you on board.</p>\n        <a href=\"${loginUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #28a745; color: white; text-decoration: none; border-radius: 4px;\">\n          Get Started\n        </a>\n      </div>\n    `,\n  }),\n\n  verifyEmail: (verifyUrl: string) => ({\n    subject: 'Verify Your Email',\n    html: `\n      <div style=\"font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;\">\n        <h2>Verify Your Email</h2>\n        <p>Please verify your email address by clicking the button below:</p>\n        <a href=\"${verifyUrl}\" style=\"display: inline-block; padding: 12px 24px; background: #007bff; color: white; text-decoration: none; border-radius: 4px;\">\n          Verify Email\n        </a>\n      </div>\n    `,\n  }),\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "mailers",
    "type": "snippet"
  },
  {
    "name": "password-argon2",
    "description": "Secure password hashing using Argon2id (OWASP Recommended)",
    "dependencies": [
      "argon2"
    ],
    "files": [
      {
        "name": "utils/password.ts",
        "path": "utils/password.ts",
        "content": "import argon2 from 'argon2';\n\n/**\n * Argon2id configuration following OWASP recommendations:\n * - memoryCost: 65536 KB (64 MiB) - memory usage\n * - timeCost: 3 - number of iterations  \n * - parallelism: 4 - degree of parallelism\n * - hashLength: 32 bytes (256 bits)\n * \n * These values provide strong security while remaining practical.\n * Adjust based on your server's capabilities.\n */\nconst ARGON2_OPTIONS: argon2.Options = {\n  type: argon2.argon2id, // Hybrid mode, resistant to side-channel and GPU attacks\n  memoryCost: 65536,     // 64 MiB\n  timeCost: 3,\n  parallelism: 4,\n  hashLength: 32,\n};\n\n/**\n * Hash a password using Argon2id\n * @param password - Plain text password to hash\n * @returns Hashed password string\n */\nexport const encryptPassword = async (password: string): Promise<string> => {\n  if (!password.length) {\n    throw new Error('Password cannot be empty');\n  }\n  return argon2.hash(password, ARGON2_OPTIONS);\n};\n\n/**\n * Verify a password against its hash\n * Uses constant-time comparison internally\n * @param password - Plain text password to verify\n * @param hash - Previously hashed password\n * @returns True if password matches\n */\nexport const verifyPassword = async (password: string, hash: string): Promise<boolean> => {\n  if (!password || !hash) {\n    return false;\n  }\n  try {\n    return await argon2.verify(hash, password);\n  } catch {\n    // Invalid hash format or other error\n    return false;\n  }\n};\n\n/**\n * Check if a hash needs to be rehashed (e.g., after updating options)\n * @param hash - Existing password hash\n * @returns True if the hash should be regenerated\n */\nexport const needsRehash = (hash: string): boolean => {\n  return argon2.needsRehash(hash, ARGON2_OPTIONS);\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "passwords",
    "type": "snippet"
  },
  {
    "name": "password-bcrypt",
    "description": "Secure password hashing using Bcrypt",
    "dependencies": [
      "bcrypt"
    ],
    "devDependencies": [
      "@types/bcrypt"
    ],
    "files": [
      {
        "name": "utils/password.ts",
        "path": "utils/password.ts",
        "content": "import bcrypt from 'bcrypt';\n\n/**\n * Salt rounds configuration:\n * - 10: ~100ms (minimum acceptable)\n * - 12: ~300ms (recommended for most applications)\n * - 14: ~1s (high security, may impact UX)\n * \n * Increase this value as hardware improves.\n * Each increment doubles the computation time.\n */\nconst SALT_ROUNDS = 12;\n\n/**\n * Hash a password using bcrypt\n * @param password - Plain text password to hash\n * @returns Hashed password string\n */\nexport const encryptPassword = async (password: string): Promise<string> => {\n  if (!password.length) {\n    throw new Error('Password cannot be empty');\n  }\n\n  // Bcrypt has a 72-byte limit on password input\n  if (Buffer.byteLength(password, 'utf8') > 72) {\n    throw new Error('Password exceeds maximum length of 72 bytes');\n  }\n\n  return bcrypt.hash(password, SALT_ROUNDS);\n};\n\n/**\n * Verify a password against its hash\n * Uses constant-time comparison internally\n * @param password - Plain text password to verify\n * @param hash - Previously hashed password\n * @returns True if password matches\n */\nexport const verifyPassword = async (password: string, hash: string): Promise<boolean> => {\n  if (!password || !hash) {\n    return false;\n  }\n  try {\n    return await bcrypt.compare(password, hash);\n  } catch {\n    // Invalid hash format or other error\n    return false;\n  }\n};\n\n/**\n * Get the number of salt rounds used in an existing hash\n * Useful for determining if a password needs rehashing\n * @param hash - Existing bcrypt hash\n * @returns Number of salt rounds\n */\nexport const getSaltRounds = (hash: string): number => {\n  return bcrypt.getRounds(hash);\n};\n\n/**\n * Check if a hash needs to be rehashed (e.g., after increasing salt rounds)\n * @param hash - Existing password hash\n * @returns True if the hash uses fewer rounds than current config\n */\nexport const needsRehash = (hash: string): boolean => {\n  try {\n    return getSaltRounds(hash) < SALT_ROUNDS;\n  } catch {\n    return true; // Invalid hash, should be rehashed\n  }\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "passwords",
    "type": "snippet"
  },
  {
    "name": "password-crypto",
    "description": "Password hashing using Node.js native crypto (Scrypt) - Zero dependencies",
    "dependencies": [],
    "files": [
      {
        "name": "utils/password.ts",
        "path": "utils/password.ts",
        "content": "import { scrypt, randomBytes, timingSafeEqual } from 'crypto';\nimport { promisify } from 'util';\n\nconst scryptAsync = promisify(scrypt);\n\n/**\n * Scrypt configuration following security best practices:\n * - Salt length: 32 bytes (256 bits)\n * - Key length: 64 bytes (512 bits)\n * - Cost (N): 2^17 = 131072 (memory and CPU cost)\n * - Block size (r): 8\n * - Parallelization (p): 1\n * \n * These values provide strong security with ~100ms hashing time.\n */\nconst SALT_LENGTH = 32;\nconst KEY_LENGTH = 64;\n\nconst SCRYPT_OPTIONS = {\n  N: 131072, // CPU/memory cost parameter (2^17)\n  r: 8,      // Block size\n  p: 1,      // Parallelization\n  maxmem: 256 * 1024 * 1024, // 256 MiB max memory\n};\n\n// Hash format version for future-proofing\nconst HASH_VERSION = 'v1';\n\n/**\n * Hash a password using scrypt\n * Format: version:N:r:p:salt:derivedKey (all hex encoded)\n * @param password - Plain text password to hash\n * @returns Hashed password string with embedded parameters\n */\nexport const encryptPassword = async (password: string): Promise<string> => {\n  if (!password.length) {\n    throw new Error('Password cannot be empty');\n  }\n  \n  const salt = randomBytes(SALT_LENGTH);\n  const derivedKey = (await scryptAsync(\n    password, \n    salt, \n    KEY_LENGTH,\n    SCRYPT_OPTIONS\n  )) as Buffer;\n  \n  // Embed parameters in hash for future-proof verification\n  return [\n    HASH_VERSION,\n    SCRYPT_OPTIONS.N,\n    SCRYPT_OPTIONS.r,\n    SCRYPT_OPTIONS.p,\n    salt.toString('hex'),\n    derivedKey.toString('hex'),\n  ].join(':');\n};\n\n/**\n * Verify a password against its hash\n * Supports both legacy format (salt:key) and new format (v1:N:r:p:salt:key)\n * @param password - Plain text password to verify\n * @param hash - Previously hashed password\n * @returns True if password matches\n */\nexport const verifyPassword = async (password: string, hash: string): Promise<boolean> => {\n  if (!password || !hash) {\n    return false;\n  }\n\n  try {\n    const parts = hash.split(':');\n    \n    let salt: Buffer;\n    let storedKey: Buffer;\n    let options = SCRYPT_OPTIONS;\n    \n    if (parts[0] === 'v1' && parts.length === 6) {\n      // New format: v1:N:r:p:salt:key\n      options = {\n        N: parseInt(parts[1], 10),\n        r: parseInt(parts[2], 10),\n        p: parseInt(parts[3], 10),\n        maxmem: 256 * 1024 * 1024,\n      };\n      salt = Buffer.from(parts[4], 'hex');\n      storedKey = Buffer.from(parts[5], 'hex');\n    } else if (parts.length === 2) {\n      // Legacy format: salt:key (uses current options)\n      salt = Buffer.from(parts[0], 'hex');\n      storedKey = Buffer.from(parts[1], 'hex');\n    } else {\n      return false;\n    }\n    \n    const derivedKey = (await scryptAsync(\n      password, \n      salt, \n      storedKey.length,\n      options\n    )) as Buffer;\n    \n    // Constant-time comparison to prevent timing attacks\n    return timingSafeEqual(storedKey, derivedKey);\n  } catch {\n    // Invalid hash format or crypto error\n    return false;\n  }\n};\n\n/**\n * Check if a hash needs to be rehashed (uses old format or weaker settings)\n * @param hash - Existing password hash\n * @returns True if the hash should be regenerated\n */\nexport const needsRehash = (hash: string): boolean => {\n  const parts = hash.split(':');\n  \n  // Legacy format needs rehash\n  if (parts.length === 2) {\n    return true;\n  }\n  \n  // Check if current settings are stronger\n  if (parts[0] === 'v1' && parts.length === 6) {\n    const N = parseInt(parts[1], 10);\n    return N < SCRYPT_OPTIONS.N;\n  }\n  \n  return true;\n};"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "passwords",
    "type": "snippet"
  },
  {
    "name": "drizzle-storage",
    "description": "Generic Storage class for Drizzle ORM with CRUD, bulk operations, and pagination",
    "dependencies": [
      "drizzle-orm"
    ],
    "files": [
      {
        "name": "libs/queries/drizzle-storage.ts",
        "path": "libs/queries/drizzle-storage.ts",
        "content": "import { eq, and, desc, asc, sql, type SQL } from 'drizzle-orm';\nimport type { PgTable, PgColumn } from 'drizzle-orm/pg-core';\n\n/**\n * Generic Storage class for Drizzle ORM (PostgreSQL)\n * Provides standardized CRUD operations with type safety\n * \n * @example\n * import { db } from '@/libs/db/drizzle';\n * import { users } from '@/db/schema';\n * \n * const userStorage = new DrizzleStorage(db, users, 'id');\n * const user = await userStorage.create({ name: 'John', email: 'john@example.com' });\n * const allUsers = await userStorage.findAll();\n * const paginatedUsers = await userStorage.paginate({ page: 1, limit: 10 });\n */\n\nexport type FilterOperator = 'eq' | 'neq' | 'gt' | 'gte' | 'lt' | 'lte' | 'like' | 'ilike';\n\nexport interface Filter<T> {\n  field: keyof T;\n  operator: FilterOperator;\n  value: unknown;\n}\n\nexport interface PaginationOptions {\n  page?: number;\n  limit?: number;\n  cursor?: string | number;\n  cursorField?: string;\n  orderBy?: string;\n  orderDir?: 'asc' | 'desc';\n}\n\nexport interface PaginatedResult<T> {\n  data: T[];\n  pagination: {\n    total: number;\n    page: number;\n    limit: number;\n    totalPages: number;\n    hasNext: boolean;\n    hasPrev: boolean;\n    nextCursor?: string | number;\n  };\n}\n\n// Generic Drizzle database type - works with any driver\ntype DrizzleDb = {\n  select: () => any;\n  insert: (table: any) => any;\n  update: (table: any) => any;\n  delete: (table: any) => any;\n};\n\nexport class DrizzleStorage<\n  TTable extends PgTable,\n  TInsert extends Record<string, unknown>,\n  TSelect extends Record<string, unknown>\n> {\n  constructor(\n    private db: DrizzleDb,\n    private table: TTable,\n    private primaryKey: keyof TSelect = 'id' as keyof TSelect\n  ) {}\n\n  /**\n   * Create a single record\n   */\n  async create(data: TInsert): Promise<TSelect> {\n    const result = await this.db\n      .insert(this.table)\n      .values(data as any)\n      .returning();\n    return result[0] as TSelect;\n  }\n\n  /**\n   * Find all records with optional filters\n   */\n  async findAll(filters?: Filter<TSelect>[]): Promise<TSelect[]> {\n    let query = this.db.select().from(this.table);\n    \n    if (filters && filters.length > 0) {\n      const conditions = this.buildConditions(filters);\n      query = query.where(and(...conditions)) as any;\n    }\n    \n    return query as unknown as Promise<TSelect[]>;\n  }\n\n  /**\n   * Find a record by ID\n   */\n  async findById(id: string | number): Promise<TSelect | null> {\n    const pkColumn = (this.table as any)[this.primaryKey] as PgColumn;\n    const result = await this.db\n      .select()\n      .from(this.table)\n      .where(eq(pkColumn, id as any))\n      .limit(1);\n    return (result[0] as TSelect) || null;\n  }\n\n  /**\n   * Find first record matching filters\n   */\n  async findOne(filters: Filter<TSelect>[]): Promise<TSelect | null> {\n    const conditions = this.buildConditions(filters);\n    const result = await this.db\n      .select()\n      .from(this.table)\n      .where(and(...conditions))\n      .limit(1);\n    return (result[0] as TSelect) || null;\n  }\n\n  /**\n   * Update a record by ID\n   */\n  async update(id: string | number, data: Partial<TInsert>): Promise<TSelect | null> {\n    const pkColumn = (this.table as any)[this.primaryKey] as PgColumn;\n    const result = await this.db\n      .update(this.table)\n      .set(data as any)\n      .where(eq(pkColumn, id as any))\n      .returning();\n    return (result[0] as TSelect) || null;\n  }\n\n  /**\n   * Hard delete a record by ID\n   */\n  async delete(id: string | number): Promise<boolean> {\n    const pkColumn = (this.table as any)[this.primaryKey] as PgColumn;\n    const result = await this.db\n      .delete(this.table)\n      .where(eq(pkColumn, id as any))\n      .returning();\n    return result.length > 0;\n  }\n\n  /**\n   * Soft delete a record (sets deletedAt timestamp)\n   */\n  async softDelete(id: string | number): Promise<TSelect | null> {\n    const pkColumn = (this.table as any)[this.primaryKey] as PgColumn;\n    const result = await this.db\n      .update(this.table)\n      .set({ deletedAt: new Date() } as any)\n      .where(eq(pkColumn, id as any))\n      .returning();\n    return (result[0] as TSelect) || null;\n  }\n\n  /**\n   * Bulk create records\n   */\n  async bulkCreate(data: TInsert[]): Promise<TSelect[]> {\n    if (data.length === 0) return [];\n    const result = await this.db\n      .insert(this.table)\n      .values(data as any[])\n      .returning();\n    return result as TSelect[];\n  }\n\n  /**\n   * Bulk update records by IDs\n   */\n  async bulkUpdate(ids: (string | number)[], data: Partial<TInsert>): Promise<TSelect[]> {\n    if (ids.length === 0) return [];\n    const pkColumn = (this.table as any)[this.primaryKey] as PgColumn;\n    \n    const result = await this.db\n      .update(this.table)\n      .set(data as any)\n      .where(sql`${pkColumn} = ANY(${ids})`)\n      .returning();\n    return result as TSelect[];\n  }\n\n  /**\n   * Paginated query with offset or cursor-based pagination\n   */\n  async paginate(options: PaginationOptions = {}): Promise<PaginatedResult<TSelect>> {\n    const {\n      page = 1,\n      limit = 10,\n      cursor,\n      cursorField = this.primaryKey as string,\n      orderBy = this.primaryKey as string,\n      orderDir = 'desc',\n    } = options;\n\n    const orderColumn = (this.table as any)[orderBy] as PgColumn;\n    const orderFn = orderDir === 'asc' ? asc : desc;\n\n    // Count total\n    const countResult = await this.db\n      .select({ count: sql<number>`count(*)` })\n      .from(this.table);\n    const total = Number(countResult[0]?.count || 0);\n\n    // Build query\n    let query = this.db.select().from(this.table);\n\n    // Cursor-based pagination\n    if (cursor) {\n      const cursorColumn = (this.table as any)[cursorField] as PgColumn;\n      const cursorOp = orderDir === 'asc' ? sql`>` : sql`<`;\n      query = query.where(sql`${cursorColumn} ${cursorOp} ${cursor}`) as any;\n    }\n\n    const results = await query\n      .orderBy(orderFn(orderColumn))\n      .limit(limit)\n      .offset(cursor ? 0 : (page - 1) * limit);\n\n    const data = results as TSelect[];\n    const totalPages = Math.ceil(total / limit);\n    const nextCursor = data.length > 0 ? (data[data.length - 1] as any)[cursorField] : undefined;\n\n    return {\n      data,\n      pagination: {\n        total,\n        page,\n        limit,\n        totalPages,\n        hasNext: cursor ? data.length === limit : page < totalPages,\n        hasPrev: cursor ? !!cursor : page > 1,\n        nextCursor,\n      },\n    };\n  }\n\n  /**\n   * Build filter conditions\n   */\n  private buildConditions(filters: Filter<TSelect>[]): SQL[] {\n    return filters.map((filter) => {\n      const column = (this.table as any)[filter.field] as PgColumn;\n      switch (filter.operator) {\n        case 'eq':\n          return eq(column, filter.value as any);\n        case 'neq':\n          return sql`${column} != ${filter.value}`;\n        case 'gt':\n          return sql`${column} > ${filter.value}`;\n        case 'gte':\n          return sql`${column} >= ${filter.value}`;\n        case 'lt':\n          return sql`${column} < ${filter.value}`;\n        case 'lte':\n          return sql`${column} <= ${filter.value}`;\n        case 'like':\n          return sql`${column} LIKE ${filter.value}`;\n        case 'ilike':\n          return sql`${column} ILIKE ${filter.value}`;\n        default:\n          return eq(column, filter.value as any);\n      }\n    });\n  }\n}\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "queries",
    "type": "snippet"
  },
  {
    "name": "mongodb-storage",
    "description": "Generic Storage class for MongoDB using native driver",
    "dependencies": [
      "mongodb"
    ],
    "files": [
      {
        "name": "libs/queries/mongodb-storage.ts",
        "path": "libs/queries/mongodb-storage.ts",
        "content": "import { Db, Collection, ObjectId, Filter, UpdateFilter, Document, WithId } from 'mongodb';\n\n/**\n * Generic Storage class for MongoDB (native driver)\n * Handles ObjectId conversion and provides cursor-based pagination\n * \n * @example\n * import { db } from '@/libs/db/mongodb';\n * \n * const userStorage = new MongoStorage(db, 'users');\n * const user = await userStorage.create({ name: 'John', email: 'john@example.com' });\n * const allUsers = await userStorage.findAll();\n */\n\nexport interface PaginationOptions<T> {\n  page?: number;\n  limit?: number;\n  cursor?: string;\n  cursorField?: keyof T;\n  orderBy?: keyof T;\n  orderDir?: 1 | -1;\n  filter?: Filter<T>;\n}\n\nexport interface PaginatedResult<T> {\n  data: T[];\n  pagination: {\n    total: number;\n    page: number;\n    limit: number;\n    totalPages: number;\n    hasNext: boolean;\n    hasPrev: boolean;\n    nextCursor?: string;\n  };\n}\n\nexport class MongoStorage<T extends Document> {\n  private collection: Collection<T>;\n\n  constructor(db: Db, collectionName: string) {\n    this.collection = db.collection<T>(collectionName);\n  }\n\n  private toObjectId(id: string | ObjectId): ObjectId {\n    return typeof id === 'string' ? new ObjectId(id) : id;\n  }\n\n  async create(data: Omit<T, '_id'>): Promise<WithId<T>> {\n    const doc = { ...data, createdAt: new Date(), updatedAt: new Date() } as any;\n    const result = await this.collection.insertOne(doc);\n    return { ...doc, _id: result.insertedId } as WithId<T>;\n  }\n\n  async findAll(filter: Filter<T> = {}): Promise<WithId<T>[]> {\n    return this.collection.find(filter).toArray();\n  }\n\n  async findById(id: string | ObjectId): Promise<WithId<T> | null> {\n    return this.collection.findOne({ _id: this.toObjectId(id) } as Filter<T>);\n  }\n\n  async findOne(filter: Filter<T>): Promise<WithId<T> | null> {\n    return this.collection.findOne(filter);\n  }\n\n  async update(id: string | ObjectId, data: Partial<T>): Promise<WithId<T> | null> {\n    const update: UpdateFilter<T> = { $set: { ...data, updatedAt: new Date() } as any };\n    await this.collection.updateOne({ _id: this.toObjectId(id) } as Filter<T>, update);\n    return this.findById(id);\n  }\n\n  async delete(id: string | ObjectId): Promise<boolean> {\n    const result = await this.collection.deleteOne({ _id: this.toObjectId(id) } as Filter<T>);\n    return result.deletedCount > 0;\n  }\n\n  async softDelete(id: string | ObjectId): Promise<WithId<T> | null> {\n    const update: UpdateFilter<T> = { $set: { deletedAt: new Date() } as any };\n    await this.collection.updateOne({ _id: this.toObjectId(id) } as Filter<T>, update);\n    return this.findById(id);\n  }\n\n  async restore(id: string | ObjectId): Promise<WithId<T> | null> {\n    const update: UpdateFilter<T> = { $unset: { deletedAt: '' } as any };\n    await this.collection.updateOne({ _id: this.toObjectId(id) } as Filter<T>, update);\n    return this.findById(id);\n  }\n\n  async bulkCreate(data: Omit<T, '_id'>[]): Promise<WithId<T>[]> {\n    if (!data.length) return [];\n    const now = new Date();\n    const docs = data.map(d => ({ ...d, createdAt: now, updatedAt: now })) as any[];\n    const result = await this.collection.insertMany(docs);\n    return docs.map((doc, i) => ({ ...doc, _id: result.insertedIds[i] })) as WithId<T>[];\n  }\n\n  async bulkUpdate(ids: (string | ObjectId)[], data: Partial<T>): Promise<number> {\n    if (!ids.length) return 0;\n    const objectIds = ids.map(id => this.toObjectId(id));\n    const update: UpdateFilter<T> = { $set: { ...data, updatedAt: new Date() } as any };\n    const result = await this.collection.updateMany({ _id: { $in: objectIds } } as Filter<T>, update);\n    return result.modifiedCount;\n  }\n\n  async bulkDelete(ids: (string | ObjectId)[]): Promise<number> {\n    if (!ids.length) return 0;\n    const objectIds = ids.map(id => this.toObjectId(id));\n    const result = await this.collection.deleteMany({ _id: { $in: objectIds } } as Filter<T>);\n    return result.deletedCount;\n  }\n\n  async paginate(opts: PaginationOptions<T> = {}): Promise<PaginatedResult<WithId<T>>> {\n    const { page = 1, limit = 10, cursor, cursorField = '_id' as keyof T, orderBy = '_id' as keyof T, orderDir = -1, filter = {} } = opts;\n\n    const total = await this.collection.countDocuments(filter);\n    \n    let query: Filter<T> = { ...filter };\n    if (cursor) {\n      const cursorOp = orderDir === 1 ? '$gt' : '$lt';\n      const cursorVal = cursorField === '_id' ? new ObjectId(cursor) : cursor;\n      query = { ...query, [cursorField]: { [cursorOp]: cursorVal } } as Filter<T>;\n    }\n\n    const skip = cursor ? 0 : (page - 1) * limit;\n    const data = await this.collection\n      .find(query)\n      .sort({ [orderBy]: orderDir } as any)\n      .skip(skip)\n      .limit(limit)\n      .toArray();\n\n    const totalPages = Math.ceil(total / limit);\n    const lastDoc = data[data.length - 1];\n    const nextCursor = lastDoc ? String((lastDoc as any)[cursorField]) : undefined;\n\n    return {\n      data,\n      pagination: { total, page, limit, totalPages, hasNext: data.length === limit, hasPrev: page > 1, nextCursor }\n    };\n  }\n\n  async count(filter: Filter<T> = {}): Promise<number> {\n    return this.collection.countDocuments(filter);\n  }\n\n  async exists(filter: Filter<T>): Promise<boolean> {\n    const count = await this.collection.countDocuments(filter, { limit: 1 });\n    return count > 0;\n  }\n\n  async aggregate<R = Document>(pipeline: Document[]): Promise<R[]> {\n    return this.collection.aggregate<R>(pipeline).toArray();\n  }\n}\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "queries",
    "type": "snippet"
  },
  {
    "name": "mysql-storage",
    "description": "Generic Storage class for raw MySQL queries using mysql2",
    "dependencies": [
      "mysql2"
    ],
    "files": [
      {
        "name": "libs/queries/mysql-storage.ts",
        "path": "libs/queries/mysql-storage.ts",
        "content": "import { Pool, PoolConnection, RowDataPacket, ResultSetHeader } from 'mysql2/promise';\n\n/**\n * Generic Storage class for raw MySQL queries\n * Uses prepared statements to prevent SQL injection\n * \n * @example\n * import { pool } from '@/libs/db/mysql';\n * \n * const userStorage = new MySqlStorage(pool, 'users', 'id');\n * const user = await userStorage.create({ name: 'John', email: 'john@example.com' });\n * const paginatedUsers = await userStorage.paginate({ page: 1, limit: 10 });\n */\n\nexport interface PaginationOptions {\n  page?: number;\n  limit?: number;\n  cursor?: string | number;\n  cursorField?: string;\n  orderBy?: string;\n  orderDir?: 'ASC' | 'DESC';\n  where?: Record<string, unknown>;\n}\n\nexport interface PaginatedResult<T> {\n  data: T[];\n  pagination: {\n    total: number;\n    page: number;\n    limit: number;\n    totalPages: number;\n    hasNext: boolean;\n    hasPrev: boolean;\n    nextCursor?: string | number;\n  };\n}\n\nexport class MySqlStorage<T extends Record<string, unknown>> {\n  constructor(\n    private pool: Pool,\n    private tableName: string,\n    private primaryKey: string = 'id'\n  ) {}\n\n  private esc(id: string): string {\n    return `\\`${id.replace(/`/g, '``')}\\``;\n  }\n\n  async create(data: Partial<T>): Promise<T> {\n    const keys = Object.keys(data);\n    const values = Object.values(data);\n    const cols = keys.map(k => this.esc(k)).join(', ');\n    const ph = keys.map(() => '?').join(', ');\n    const [result] = await this.pool.execute<ResultSetHeader>(\n      `INSERT INTO ${this.esc(this.tableName)} (${cols}) VALUES (${ph})`, values\n    );\n    return this.findById(result.insertId) as Promise<T>;\n  }\n\n  async findAll(where?: Record<string, unknown>): Promise<T[]> {\n    let q = `SELECT * FROM ${this.esc(this.tableName)}`;\n    const v: unknown[] = [];\n    if (where && Object.keys(where).length) {\n      const conds = Object.keys(where).map(k => `${this.esc(k)} = ?`);\n      q += ` WHERE ${conds.join(' AND ')}`;\n      v.push(...Object.values(where));\n    }\n    const [rows] = await this.pool.execute<RowDataPacket[]>(q, v);\n    return rows as T[];\n  }\n\n  async findById(id: string | number): Promise<T | null> {\n    const [rows] = await this.pool.execute<RowDataPacket[]>(\n      `SELECT * FROM ${this.esc(this.tableName)} WHERE ${this.esc(this.primaryKey)} = ? LIMIT 1`, [id]\n    );\n    return (rows[0] as T) || null;\n  }\n\n  async findOne(where: Record<string, unknown>): Promise<T | null> {\n    const conds = Object.keys(where).map(k => `${this.esc(k)} = ?`);\n    const [rows] = await this.pool.execute<RowDataPacket[]>(\n      `SELECT * FROM ${this.esc(this.tableName)} WHERE ${conds.join(' AND ')} LIMIT 1`,\n      Object.values(where)\n    );\n    return (rows[0] as T) || null;\n  }\n\n  async update(id: string | number, data: Partial<T>): Promise<T | null> {\n    const keys = Object.keys(data);\n    if (!keys.length) return this.findById(id);\n    const set = keys.map(k => `${this.esc(k)} = ?`).join(', ');\n    await this.pool.execute(\n      `UPDATE ${this.esc(this.tableName)} SET ${set} WHERE ${this.esc(this.primaryKey)} = ?`,\n      [...Object.values(data), id]\n    );\n    return this.findById(id);\n  }\n\n  async delete(id: string | number): Promise<boolean> {\n    const [r] = await this.pool.execute<ResultSetHeader>(\n      `DELETE FROM ${this.esc(this.tableName)} WHERE ${this.esc(this.primaryKey)} = ?`, [id]\n    );\n    return r.affectedRows > 0;\n  }\n\n  async softDelete(id: string | number): Promise<T | null> {\n    await this.pool.execute(\n      `UPDATE ${this.esc(this.tableName)} SET deleted_at = NOW() WHERE ${this.esc(this.primaryKey)} = ?`, [id]\n    );\n    return this.findById(id);\n  }\n\n  async bulkCreate(data: Partial<T>[]): Promise<T[]> {\n    if (!data.length) return [];\n    const keys = Object.keys(data[0]);\n    const cols = keys.map(k => this.esc(k)).join(', ');\n    const ph = data.map(() => `(${keys.map(() => '?').join(', ')})`).join(', ');\n    const vals = data.flatMap(r => keys.map(k => (r as any)[k]));\n    const [res] = await this.pool.execute<ResultSetHeader>(\n      `INSERT INTO ${this.esc(this.tableName)} (${cols}) VALUES ${ph}`, vals\n    );\n    const ids = Array.from({ length: data.length }, (_, i) => res.insertId + i);\n    const [rows] = await this.pool.execute<RowDataPacket[]>(\n      `SELECT * FROM ${this.esc(this.tableName)} WHERE ${this.esc(this.primaryKey)} IN (${ids.map(() => '?').join(',')})`, ids\n    );\n    return rows as T[];\n  }\n\n  async bulkUpdate(ids: (string | number)[], data: Partial<T>): Promise<number> {\n    if (!ids.length) return 0;\n    const set = Object.keys(data).map(k => `${this.esc(k)} = ?`).join(', ');\n    const [r] = await this.pool.execute<ResultSetHeader>(\n      `UPDATE ${this.esc(this.tableName)} SET ${set} WHERE ${this.esc(this.primaryKey)} IN (${ids.map(() => '?').join(',')})`,\n      [...Object.values(data), ...ids]\n    );\n    return r.affectedRows;\n  }\n\n  async paginate(opts: PaginationOptions = {}): Promise<PaginatedResult<T>> {\n    const { page = 1, limit = 10, cursor, cursorField = this.primaryKey, orderBy = this.primaryKey, orderDir = 'DESC', where = {} } = opts;\n    const [[{ count: total }]] = await this.pool.execute<RowDataPacket[]>(\n      `SELECT COUNT(*) as count FROM ${this.esc(this.tableName)}`\n    ) as any;\n    const params: unknown[] = [];\n    let q = `SELECT * FROM ${this.esc(this.tableName)}`;\n    const conds: string[] = [];\n    if (Object.keys(where).length) {\n      conds.push(...Object.keys(where).map(k => `${this.esc(k)} = ?`));\n      params.push(...Object.values(where));\n    }\n    if (cursor) {\n      conds.push(`${this.esc(cursorField)} ${orderDir === 'ASC' ? '>' : '<'} ?`);\n      params.push(cursor);\n    }\n    if (conds.length) q += ` WHERE ${conds.join(' AND ')}`;\n    q += ` ORDER BY ${this.esc(orderBy)} ${orderDir} LIMIT ?`;\n    params.push(limit);\n    if (!cursor) { q += ` OFFSET ?`; params.push((page - 1) * limit); }\n    const [rows] = await this.pool.execute<RowDataPacket[]>(q, params);\n    const data = rows as T[];\n    const totalPages = Math.ceil(total / limit);\n    return {\n      data,\n      pagination: { total, page, limit, totalPages, hasNext: data.length === limit, hasPrev: page > 1, nextCursor: data.length ? (data[data.length - 1] as any)[cursorField] : undefined }\n    };\n  }\n\n  async transaction<R>(fn: (conn: PoolConnection) => Promise<R>): Promise<R> {\n    const conn = await this.pool.getConnection();\n    try { await conn.beginTransaction(); const r = await fn(conn); await conn.commit(); return r; }\n    catch (e) { await conn.rollback(); throw e; }\n    finally { conn.release(); }\n  }\n}\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "queries",
    "type": "snippet"
  },
  {
    "name": "pg-storage",
    "description": "Generic Storage class for raw PostgreSQL queries using pg Pool",
    "dependencies": [
      "pg"
    ],
    "devDependencies": [
      "@types/pg"
    ],
    "files": [
      {
        "name": "libs/queries/pg-storage.ts",
        "path": "libs/queries/pg-storage.ts",
        "content": "import { Pool, PoolClient } from 'pg';\n\n/**\n * Generic Storage class for raw PostgreSQL queries\n * Uses parameterized queries to prevent SQL injection\n * \n * @example\n * import { pool } from '@/libs/db/postgres';\n * \n * const userStorage = new PgStorage(pool, 'users', 'id');\n * const user = await userStorage.create({ name: 'John', email: 'john@example.com' });\n * const paginatedUsers = await userStorage.paginate({ page: 1, limit: 10 });\n */\n\nexport interface PaginationOptions {\n  page?: number;\n  limit?: number;\n  cursor?: string | number;\n  cursorField?: string;\n  orderBy?: string;\n  orderDir?: 'ASC' | 'DESC';\n  where?: Record<string, unknown>;\n}\n\nexport interface PaginatedResult<T> {\n  data: T[];\n  pagination: {\n    total: number;\n    page: number;\n    limit: number;\n    totalPages: number;\n    hasNext: boolean;\n    hasPrev: boolean;\n    nextCursor?: string | number;\n  };\n}\n\nexport class PgStorage<T extends Record<string, unknown>> {\n  constructor(\n    private pool: Pool,\n    private tableName: string,\n    private primaryKey: string = 'id'\n  ) {\n    // Validate table name to prevent SQL injection\n    if (!/^[a-zA-Z_][a-zA-Z0-9_]*$/.test(tableName)) {\n      throw new Error('Invalid table name');\n    }\n  }\n\n  /**\n   * Create a single record\n   */\n  async create(data: Omit<T, 'id' | 'createdAt' | 'updatedAt'>): Promise<T> {\n    const keys = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = keys.map((_, i) => `$${i + 1}`).join(', ');\n    const columns = keys.map(this.escapeIdentifier).join(', ');\n\n    const query = `\n      INSERT INTO ${this.escapeIdentifier(this.tableName)} (${columns})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n\n    const result = await this.pool.query<T>(query, values);\n    return result.rows[0];\n  }\n\n  /**\n   * Find all records with optional filters\n   */\n  async findAll(where?: Record<string, unknown>): Promise<T[]> {\n    let query = `SELECT * FROM ${this.escapeIdentifier(this.tableName)}`;\n    const values: unknown[] = [];\n\n    if (where && Object.keys(where).length > 0) {\n      const { whereClause, params } = this.buildWhereClause(where);\n      query += ` WHERE ${whereClause}`;\n      values.push(...params);\n    }\n\n    const result = await this.pool.query<T>(query, values);\n    return result.rows;\n  }\n\n  /**\n   * Find a record by ID\n   */\n  async findById(id: string | number): Promise<T | null> {\n    const query = `\n      SELECT * FROM ${this.escapeIdentifier(this.tableName)}\n      WHERE ${this.escapeIdentifier(this.primaryKey)} = $1\n      LIMIT 1\n    `;\n\n    const result = await this.pool.query<T>(query, [id]);\n    return result.rows[0] || null;\n  }\n\n  /**\n   * Find first record matching filters\n   */\n  async findOne(where: Record<string, unknown>): Promise<T | null> {\n    const { whereClause, params } = this.buildWhereClause(where);\n    const query = `\n      SELECT * FROM ${this.escapeIdentifier(this.tableName)}\n      WHERE ${whereClause}\n      LIMIT 1\n    `;\n\n    const result = await this.pool.query<T>(query, params);\n    return result.rows[0] || null;\n  }\n\n  /**\n   * Update a record by ID\n   */\n  async update(id: string | number, data: Partial<Omit<T, 'id'>>): Promise<T | null> {\n    const keys = Object.keys(data);\n    const values = Object.values(data);\n    \n    if (keys.length === 0) return this.findById(id);\n\n    const setClause = keys\n      .map((key, i) => `${this.escapeIdentifier(key)} = $${i + 1}`)\n      .join(', ');\n\n    const query = `\n      UPDATE ${this.escapeIdentifier(this.tableName)}\n      SET ${setClause}, updated_at = NOW()\n      WHERE ${this.escapeIdentifier(this.primaryKey)} = $${keys.length + 1}\n      RETURNING *\n    `;\n\n    const result = await this.pool.query<T>(query, [...values, id]);\n    return result.rows[0] || null;\n  }\n\n  /**\n   * Hard delete a record by ID\n   */\n  async delete(id: string | number): Promise<boolean> {\n    const query = `\n      DELETE FROM ${this.escapeIdentifier(this.tableName)}\n      WHERE ${this.escapeIdentifier(this.primaryKey)} = $1\n      RETURNING ${this.escapeIdentifier(this.primaryKey)}\n    `;\n\n    const result = await this.pool.query(query, [id]);\n    return result.rowCount !== null && result.rowCount > 0;\n  }\n\n  /**\n   * Soft delete a record (sets deleted_at timestamp)\n   */\n  async softDelete(id: string | number): Promise<T | null> {\n    const query = `\n      UPDATE ${this.escapeIdentifier(this.tableName)}\n      SET deleted_at = NOW()\n      WHERE ${this.escapeIdentifier(this.primaryKey)} = $1\n      RETURNING *\n    `;\n\n    const result = await this.pool.query<T>(query, [id]);\n    return result.rows[0] || null;\n  }\n\n  /**\n   * Restore a soft-deleted record\n   */\n  async restore(id: string | number): Promise<T | null> {\n    const query = `\n      UPDATE ${this.escapeIdentifier(this.tableName)}\n      SET deleted_at = NULL\n      WHERE ${this.escapeIdentifier(this.primaryKey)} = $1\n      RETURNING *\n    `;\n\n    const result = await this.pool.query<T>(query, [id]);\n    return result.rows[0] || null;\n  }\n\n  /**\n   * Bulk create records\n   */\n  async bulkCreate(data: Omit<T, 'id' | 'createdAt' | 'updatedAt'>[]): Promise<T[]> {\n    if (data.length === 0) return [];\n\n    const keys = Object.keys(data[0]);\n    const columns = keys.map(this.escapeIdentifier).join(', ');\n    \n    let paramIndex = 1;\n    const valueRows = data.map((row) => {\n      const placeholders = keys.map(() => `$${paramIndex++}`).join(', ');\n      return `(${placeholders})`;\n    });\n\n    const values = data.flatMap((row) => keys.map((key) => (row as any)[key]));\n\n    const query = `\n      INSERT INTO ${this.escapeIdentifier(this.tableName)} (${columns})\n      VALUES ${valueRows.join(', ')}\n      RETURNING *\n    `;\n\n    const result = await this.pool.query<T>(query, values);\n    return result.rows;\n  }\n\n  /**\n   * Bulk update records by IDs\n   */\n  async bulkUpdate(ids: (string | number)[], data: Partial<Omit<T, 'id'>>): Promise<T[]> {\n    if (ids.length === 0) return [];\n\n    const keys = Object.keys(data);\n    const values = Object.values(data);\n    \n    const setClause = keys\n      .map((key, i) => `${this.escapeIdentifier(key)} = $${i + 1}`)\n      .join(', ');\n\n    const query = `\n      UPDATE ${this.escapeIdentifier(this.tableName)}\n      SET ${setClause}, updated_at = NOW()\n      WHERE ${this.escapeIdentifier(this.primaryKey)} = ANY($${keys.length + 1})\n      RETURNING *\n    `;\n\n    const result = await this.pool.query<T>(query, [...values, ids]);\n    return result.rows;\n  }\n\n  /**\n   * Bulk delete records by IDs\n   */\n  async bulkDelete(ids: (string | number)[]): Promise<number> {\n    if (ids.length === 0) return 0;\n\n    const query = `\n      DELETE FROM ${this.escapeIdentifier(this.tableName)}\n      WHERE ${this.escapeIdentifier(this.primaryKey)} = ANY($1)\n    `;\n\n    const result = await this.pool.query(query, [ids]);\n    return result.rowCount || 0;\n  }\n\n  /**\n   * Paginated query with offset or cursor-based pagination\n   */\n  async paginate(options: PaginationOptions = {}): Promise<PaginatedResult<T>> {\n    const {\n      page = 1,\n      limit = 10,\n      cursor,\n      cursorField = this.primaryKey,\n      orderBy = this.primaryKey,\n      orderDir = 'DESC',\n      where = {},\n    } = options;\n\n    // Count total\n    let countQuery = `SELECT COUNT(*) FROM ${this.escapeIdentifier(this.tableName)}`;\n    const countParams: unknown[] = [];\n    \n    if (Object.keys(where).length > 0) {\n      const { whereClause, params } = this.buildWhereClause(where);\n      countQuery += ` WHERE ${whereClause}`;\n      countParams.push(...params);\n    }\n    \n    const countResult = await this.pool.query(countQuery, countParams);\n    const total = parseInt(countResult.rows[0].count, 10);\n\n    // Build data query\n    const params: unknown[] = [];\n    let dataQuery = `SELECT * FROM ${this.escapeIdentifier(this.tableName)}`;\n    \n    const conditions: string[] = [];\n    \n    if (Object.keys(where).length > 0) {\n      const { whereClause, params: whereParams } = this.buildWhereClause(where, params.length);\n      conditions.push(whereClause);\n      params.push(...whereParams);\n    }\n\n    if (cursor) {\n      const cursorOp = orderDir === 'ASC' ? '>' : '<';\n      params.push(cursor);\n      conditions.push(`${this.escapeIdentifier(cursorField)} ${cursorOp} $${params.length}`);\n    }\n\n    if (conditions.length > 0) {\n      dataQuery += ` WHERE ${conditions.join(' AND ')}`;\n    }\n\n    dataQuery += ` ORDER BY ${this.escapeIdentifier(orderBy)} ${orderDir}`;\n    \n    params.push(limit);\n    dataQuery += ` LIMIT $${params.length}`;\n    \n    if (!cursor) {\n      params.push((page - 1) * limit);\n      dataQuery += ` OFFSET $${params.length}`;\n    }\n\n    const dataResult = await this.pool.query<T>(dataQuery, params);\n    const data = dataResult.rows;\n\n    const totalPages = Math.ceil(total / limit);\n    const nextCursor = data.length > 0 ? (data[data.length - 1] as any)[cursorField] : undefined;\n\n    return {\n      data,\n      pagination: {\n        total,\n        page,\n        limit,\n        totalPages,\n        hasNext: cursor ? data.length === limit : page < totalPages,\n        hasPrev: cursor ? !!cursor : page > 1,\n        nextCursor,\n      },\n    };\n  }\n\n  /**\n   * Count records\n   */\n  async count(where?: Record<string, unknown>): Promise<number> {\n    let query = `SELECT COUNT(*) FROM ${this.escapeIdentifier(this.tableName)}`;\n    const params: unknown[] = [];\n\n    if (where && Object.keys(where).length > 0) {\n      const { whereClause, params: whereParams } = this.buildWhereClause(where);\n      query += ` WHERE ${whereClause}`;\n      params.push(...whereParams);\n    }\n\n    const result = await this.pool.query(query, params);\n    return parseInt(result.rows[0].count, 10);\n  }\n\n  /**\n   * Execute raw query\n   */\n  async raw<R>(query: string, params?: unknown[]): Promise<R[]> {\n    const result = await this.pool.query<R>(query, params);\n    return result.rows;\n  }\n\n  /**\n   * Execute operations in a transaction\n   */\n  async transaction<R>(fn: (client: PoolClient) => Promise<R>): Promise<R> {\n    const client = await this.pool.connect();\n    try {\n      await client.query('BEGIN');\n      const result = await fn(client);\n      await client.query('COMMIT');\n      return result;\n    } catch (error) {\n      await client.query('ROLLBACK');\n      throw error;\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Build WHERE clause from object\n   */\n  private buildWhereClause(\n    where: Record<string, unknown>,\n    startIndex = 0\n  ): { whereClause: string; params: unknown[] } {\n    const keys = Object.keys(where);\n    const params = Object.values(where);\n    \n    const conditions = keys.map((key, i) => \n      `${this.escapeIdentifier(key)} = $${startIndex + i + 1}`\n    );\n\n    return {\n      whereClause: conditions.join(' AND '),\n      params,\n    };\n  }\n\n  /**\n   * Escape identifier to prevent SQL injection\n   */\n  private escapeIdentifier(identifier: string): string {\n    return `\"${identifier.replace(/\"/g, '\"\"')}\"`;\n  }\n}\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "queries",
    "type": "snippet"
  },
  {
    "name": "prisma-storage",
    "description": "Generic Storage class for Prisma ORM with CRUD, bulk operations, and pagination",
    "dependencies": [
      "@prisma/client"
    ],
    "devDependencies": [
      "prisma"
    ],
    "files": [
      {
        "name": "libs/queries/prisma-storage.ts",
        "path": "libs/queries/prisma-storage.ts",
        "content": "import { PrismaClient, Prisma } from '@prisma/client';\n\n/**\n * Generic Storage class for Prisma ORM\n * Provides standardized CRUD operations with full type safety\n * \n * @example\n * import { prisma } from '@/libs/db/prisma';\n * \n * const userStorage = new PrismaStorage(prisma, 'user');\n * const user = await userStorage.create({ name: 'John', email: 'john@example.com' });\n * const paginatedUsers = await userStorage.paginate({ page: 1, limit: 10 });\n */\n\nexport interface PaginationOptions {\n  page?: number;\n  limit?: number;\n  cursor?: string | number;\n  cursorField?: string;\n  orderBy?: string;\n  orderDir?: 'asc' | 'desc';\n}\n\nexport interface PaginatedResult<T> {\n  data: T[];\n  pagination: {\n    total: number;\n    page: number;\n    limit: number;\n    totalPages: number;\n    hasNext: boolean;\n    hasPrev: boolean;\n    nextCursor?: string | number;\n  };\n}\n\nexport interface FilterOptions {\n  where?: Record<string, unknown>;\n  include?: Record<string, boolean | object>;\n  select?: Record<string, boolean>;\n}\n\nexport class PrismaStorage<\n  TModel extends keyof PrismaClient,\n  TCreate = unknown,\n  TUpdate = unknown,\n  TRecord = unknown\n> {\n  private model: any;\n\n  constructor(\n    private prisma: PrismaClient,\n    private modelName: TModel,\n    private primaryKey: string = 'id'\n  ) {\n    this.model = (prisma as any)[modelName];\n  }\n\n  /**\n   * Create a single record\n   */\n  async create(data: TCreate, options?: { include?: Record<string, boolean | object> }): Promise<TRecord> {\n    return this.model.create({\n      data,\n      ...options,\n    });\n  }\n\n  /**\n   * Find all records with optional filters\n   */\n  async findAll(options?: FilterOptions): Promise<TRecord[]> {\n    return this.model.findMany({\n      where: options?.where,\n      include: options?.include,\n      select: options?.select,\n    });\n  }\n\n  /**\n   * Find a record by ID\n   */\n  async findById(\n    id: string | number,\n    options?: { include?: Record<string, boolean | object> }\n  ): Promise<TRecord | null> {\n    return this.model.findUnique({\n      where: { [this.primaryKey]: id },\n      ...options,\n    });\n  }\n\n  /**\n   * Find first record matching filters\n   */\n  async findOne(\n    where: Record<string, unknown>,\n    options?: { include?: Record<string, boolean | object> }\n  ): Promise<TRecord | null> {\n    return this.model.findFirst({\n      where,\n      ...options,\n    });\n  }\n\n  /**\n   * Update a record by ID\n   */\n  async update(\n    id: string | number,\n    data: TUpdate,\n    options?: { include?: Record<string, boolean | object> }\n  ): Promise<TRecord> {\n    return this.model.update({\n      where: { [this.primaryKey]: id },\n      data,\n      ...options,\n    });\n  }\n\n  /**\n   * Hard delete a record by ID\n   */\n  async delete(id: string | number): Promise<TRecord> {\n    return this.model.delete({\n      where: { [this.primaryKey]: id },\n    });\n  }\n\n  /**\n   * Soft delete a record (sets deletedAt timestamp)\n   * Requires `deletedAt` field in your schema\n   */\n  async softDelete(id: string | number): Promise<TRecord> {\n    return this.model.update({\n      where: { [this.primaryKey]: id },\n      data: { deletedAt: new Date() },\n    });\n  }\n\n  /**\n   * Restore a soft-deleted record\n   */\n  async restore(id: string | number): Promise<TRecord> {\n    return this.model.update({\n      where: { [this.primaryKey]: id },\n      data: { deletedAt: null },\n    });\n  }\n\n  /**\n   * Bulk create records using transaction\n   */\n  async bulkCreate(data: TCreate[]): Promise<TRecord[]> {\n    return this.prisma.$transaction(\n      data.map((item) => this.model.create({ data: item }))\n    );\n  }\n\n  /**\n   * Bulk update records by IDs\n   */\n  async bulkUpdate(ids: (string | number)[], data: TUpdate): Promise<{ count: number }> {\n    return this.model.updateMany({\n      where: { [this.primaryKey]: { in: ids } },\n      data,\n    });\n  }\n\n  /**\n   * Bulk delete records by IDs\n   */\n  async bulkDelete(ids: (string | number)[]): Promise<{ count: number }> {\n    return this.model.deleteMany({\n      where: { [this.primaryKey]: { in: ids } },\n    });\n  }\n\n  /**\n   * Paginated query with offset or cursor-based pagination\n   */\n  async paginate(options: PaginationOptions & FilterOptions = {}): Promise<PaginatedResult<TRecord>> {\n    const {\n      page = 1,\n      limit = 10,\n      cursor,\n      cursorField = this.primaryKey,\n      orderBy = this.primaryKey,\n      orderDir = 'desc',\n      where,\n      include,\n    } = options;\n\n    // Count total\n    const total = await this.model.count({ where });\n\n    // Build query options\n    const queryOptions: any = {\n      where,\n      include,\n      orderBy: { [orderBy]: orderDir },\n      take: limit,\n    };\n\n    // Cursor-based pagination\n    if (cursor) {\n      queryOptions.cursor = { [cursorField]: cursor };\n      queryOptions.skip = 1; // Skip the cursor itself\n    } else {\n      // Offset-based pagination\n      queryOptions.skip = (page - 1) * limit;\n    }\n\n    const data = await this.model.findMany(queryOptions);\n    const totalPages = Math.ceil(total / limit);\n    const nextCursor = data.length > 0 ? data[data.length - 1][cursorField] : undefined;\n\n    return {\n      data,\n      pagination: {\n        total,\n        page,\n        limit,\n        totalPages,\n        hasNext: cursor ? data.length === limit : page < totalPages,\n        hasPrev: cursor ? !!cursor : page > 1,\n        nextCursor,\n      },\n    };\n  }\n\n  /**\n   * Count records\n   */\n  async count(where?: Record<string, unknown>): Promise<number> {\n    return this.model.count({ where });\n  }\n\n  /**\n   * Check if record exists\n   */\n  async exists(where: Record<string, unknown>): Promise<boolean> {\n    const count = await this.model.count({ where });\n    return count > 0;\n  }\n\n  /**\n   * Upsert (create or update)\n   */\n  async upsert(\n    where: Record<string, unknown>,\n    create: TCreate,\n    update: TUpdate\n  ): Promise<TRecord> {\n    return this.model.upsert({\n      where,\n      create,\n      update,\n    });\n  }\n\n  /**\n   * Execute operations in a transaction\n   */\n  async transaction<T>(fn: (tx: Prisma.TransactionClient) => Promise<T>): Promise<T> {\n    return this.prisma.$transaction(fn);\n  }\n}\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "queries",
    "type": "snippet"
  },
  {
    "name": "sequelize-storage",
    "description": "Generic Storage class for Sequelize ORM with CRUD, bulk operations, and pagination",
    "dependencies": [
      "sequelize"
    ],
    "files": [
      {
        "name": "libs/queries/sequelize-storage.ts",
        "path": "libs/queries/sequelize-storage.ts",
        "content": "import {\n  Model,\n  ModelStatic,\n  WhereOptions,\n  FindOptions,\n  CreateOptions,\n  UpdateOptions,\n  DestroyOptions,\n  Op,\n  Sequelize,\n} from 'sequelize';\n\n/**\n * Generic Storage class for Sequelize ORM\n * Provides standardized CRUD operations\n * \n * @example\n * import { sequelize } from '@/libs/db/sequelize';\n * import { User } from '@/models/User';\n * \n * const userStorage = new SequelizeStorage(User, sequelize);\n * const user = await userStorage.create({ name: 'John', email: 'john@example.com' });\n * const paginatedUsers = await userStorage.paginate({ page: 1, limit: 10 });\n */\n\nexport interface PaginationOptions<T> {\n  page?: number;\n  limit?: number;\n  cursor?: string | number;\n  cursorField?: keyof T;\n  orderBy?: keyof T;\n  orderDir?: 'ASC' | 'DESC';\n  where?: WhereOptions<T>;\n  include?: FindOptions['include'];\n}\n\nexport interface PaginatedResult<T> {\n  data: T[];\n  pagination: {\n    total: number;\n    page: number;\n    limit: number;\n    totalPages: number;\n    hasNext: boolean;\n    hasPrev: boolean;\n    nextCursor?: string | number;\n  };\n}\n\nexport class SequelizeStorage<\n  TModel extends Model,\n  TAttributes = TModel['_attributes'],\n  TCreationAttributes = TModel['_creationAttributes']\n> {\n  constructor(\n    private model: ModelStatic<TModel>,\n    private sequelize: Sequelize,\n    private primaryKey: keyof TAttributes = 'id' as keyof TAttributes\n  ) {}\n\n  /**\n   * Create a single record\n   */\n  async create(\n    data: TCreationAttributes,\n    options?: CreateOptions\n  ): Promise<TModel> {\n    return this.model.create(data as any, options);\n  }\n\n  /**\n   * Find all records with optional filters\n   */\n  async findAll(options?: FindOptions<TAttributes>): Promise<TModel[]> {\n    return this.model.findAll(options);\n  }\n\n  /**\n   * Find a record by ID\n   */\n  async findById(\n    id: string | number,\n    options?: Omit<FindOptions<TAttributes>, 'where'>\n  ): Promise<TModel | null> {\n    return this.model.findByPk(id, options);\n  }\n\n  /**\n   * Find first record matching filters\n   */\n  async findOne(options: FindOptions<TAttributes>): Promise<TModel | null> {\n    return this.model.findOne(options);\n  }\n\n  /**\n   * Update a record by ID\n   */\n  async update(\n    id: string | number,\n    data: Partial<TAttributes>,\n    options?: Omit<UpdateOptions<TAttributes>, 'where'>\n  ): Promise<TModel | null> {\n    const [affectedCount] = await this.model.update(data as any, {\n      where: { [this.primaryKey]: id } as WhereOptions<TAttributes>,\n      ...options,\n    });\n    \n    if (affectedCount === 0) return null;\n    return this.findById(id);\n  }\n\n  /**\n   * Hard delete a record by ID\n   */\n  async delete(id: string | number, options?: DestroyOptions<TAttributes>): Promise<boolean> {\n    const affectedCount = await this.model.destroy({\n      where: { [this.primaryKey]: id } as WhereOptions<TAttributes>,\n      ...options,\n    });\n    return affectedCount > 0;\n  }\n\n  /**\n   * Soft delete a record (requires paranoid: true in model)\n   * Or manually sets deletedAt if not using paranoid\n   */\n  async softDelete(id: string | number): Promise<TModel | null> {\n    // If model is paranoid, destroy will soft delete\n    if ((this.model as any).options?.paranoid) {\n      await this.model.destroy({\n        where: { [this.primaryKey]: id } as WhereOptions<TAttributes>,\n      });\n      return this.findById(id, { paranoid: false } as any);\n    }\n    \n    // Manual soft delete\n    return this.update(id, { deletedAt: new Date() } as any);\n  }\n\n  /**\n   * Restore a soft-deleted record\n   */\n  async restore(id: string | number): Promise<TModel | null> {\n    if ((this.model as any).options?.paranoid) {\n      await this.model.restore({\n        where: { [this.primaryKey]: id } as WhereOptions<TAttributes>,\n      } as any);\n      return this.findById(id);\n    }\n    \n    return this.update(id, { deletedAt: null } as any);\n  }\n\n  /**\n   * Bulk create records\n   */\n  async bulkCreate(\n    data: TCreationAttributes[],\n    options?: CreateOptions\n  ): Promise<TModel[]> {\n    return this.model.bulkCreate(data as any[], options);\n  }\n\n  /**\n   * Bulk update records by IDs\n   */\n  async bulkUpdate(\n    ids: (string | number)[],\n    data: Partial<TAttributes>\n  ): Promise<number> {\n    const [affectedCount] = await this.model.update(data as any, {\n      where: { [this.primaryKey]: { [Op.in]: ids } } as WhereOptions<TAttributes>,\n    });\n    return affectedCount;\n  }\n\n  /**\n   * Bulk delete records by IDs\n   */\n  async bulkDelete(ids: (string | number)[]): Promise<number> {\n    return this.model.destroy({\n      where: { [this.primaryKey]: { [Op.in]: ids } } as WhereOptions<TAttributes>,\n    });\n  }\n\n  /**\n   * Paginated query with offset or cursor-based pagination\n   */\n  async paginate(options: PaginationOptions<TAttributes> = {}): Promise<PaginatedResult<TModel>> {\n    const {\n      page = 1,\n      limit = 10,\n      cursor,\n      cursorField = this.primaryKey,\n      orderBy = this.primaryKey,\n      orderDir = 'DESC',\n      where = {},\n      include,\n    } = options;\n\n    // Build where clause for cursor\n    let whereClause = { ...where } as WhereOptions<TAttributes>;\n    if (cursor) {\n      const cursorOp = orderDir === 'ASC' ? Op.gt : Op.lt;\n      whereClause = {\n        ...whereClause,\n        [cursorField]: { [cursorOp]: cursor },\n      } as WhereOptions<TAttributes>;\n    }\n\n    // Get total count\n    const total = await this.model.count({ where: where as WhereOptions<TAttributes> });\n\n    // Execute query\n    const { rows: data } = await this.model.findAndCountAll({\n      where: whereClause,\n      include,\n      order: [[orderBy as string, orderDir]],\n      limit,\n      offset: cursor ? 0 : (page - 1) * limit,\n    });\n\n    const totalPages = Math.ceil(total / limit);\n    const nextCursor = data.length > 0 \n      ? (data[data.length - 1] as any)[cursorField] \n      : undefined;\n\n    return {\n      data,\n      pagination: {\n        total,\n        page,\n        limit,\n        totalPages,\n        hasNext: cursor ? data.length === limit : page < totalPages,\n        hasPrev: cursor ? !!cursor : page > 1,\n        nextCursor,\n      },\n    };\n  }\n\n  /**\n   * Count records\n   */\n  async count(where?: WhereOptions<TAttributes>): Promise<number> {\n    return this.model.count({ where });\n  }\n\n  /**\n   * Check if record exists\n   */\n  async exists(where: WhereOptions<TAttributes>): Promise<boolean> {\n    const count = await this.model.count({ where });\n    return count > 0;\n  }\n\n  /**\n   * Find or create a record\n   */\n  async findOrCreate(\n    where: WhereOptions<TAttributes>,\n    defaults: TCreationAttributes\n  ): Promise<[TModel, boolean]> {\n    return this.model.findOrCreate({\n      where,\n      defaults: defaults as any,\n    });\n  }\n\n  /**\n   * Execute operations in a transaction\n   */\n  async transaction<T>(fn: (t: any) => Promise<T>): Promise<T> {\n    return this.sequelize.transaction(fn);\n  }\n}\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "queries",
    "type": "snippet"
  },
  {
    "name": "sqlite-storage",
    "description": "Generic Storage class for SQLite using better-sqlite3",
    "dependencies": [
      "better-sqlite3"
    ],
    "devDependencies": [
      "@types/better-sqlite3"
    ],
    "files": [
      {
        "name": "libs/queries/sqlite-storage.ts",
        "path": "libs/queries/sqlite-storage.ts",
        "content": "import { Database as DatabaseType } from 'better-sqlite3';\n\n/**\n * Generic Storage class for SQLite (better-sqlite3)\n * Synchronous API for maximum performance\n * \n * @example\n * import { db } from '@/libs/db/sqlite';\n * \n * const userStorage = new SqliteStorage(db, 'users', 'id');\n * const user = userStorage.create({ name: 'John', email: 'john@example.com' });\n * const paginatedUsers = userStorage.paginate({ page: 1, limit: 10 });\n */\n\nexport interface PaginationOptions {\n  page?: number;\n  limit?: number;\n  cursor?: string | number;\n  cursorField?: string;\n  orderBy?: string;\n  orderDir?: 'ASC' | 'DESC';\n  where?: Record<string, unknown>;\n}\n\nexport interface PaginatedResult<T> {\n  data: T[];\n  pagination: {\n    total: number;\n    page: number;\n    limit: number;\n    totalPages: number;\n    hasNext: boolean;\n    hasPrev: boolean;\n    nextCursor?: string | number;\n  };\n}\n\nexport class SqliteStorage<T extends Record<string, unknown>> {\n  constructor(\n    private db: DatabaseType,\n    private tableName: string,\n    private primaryKey: string = 'id'\n  ) {}\n\n  private esc(id: string): string {\n    return `\"${id.replace(/\"/g, '\"\"')}\"`;\n  }\n\n  create(data: Partial<T>): T {\n    const keys = Object.keys(data);\n    const cols = keys.map(k => this.esc(k)).join(', ');\n    const ph = keys.map(() => '?').join(', ');\n    const stmt = this.db.prepare(\n      `INSERT INTO ${this.esc(this.tableName)} (${cols}) VALUES (${ph}) RETURNING *`\n    );\n    return stmt.get(...Object.values(data)) as T;\n  }\n\n  findAll(where?: Record<string, unknown>): T[] {\n    let q = `SELECT * FROM ${this.esc(this.tableName)}`;\n    const v: unknown[] = [];\n    if (where && Object.keys(where).length) {\n      const conds = Object.keys(where).map(k => `${this.esc(k)} = ?`);\n      q += ` WHERE ${conds.join(' AND ')}`;\n      v.push(...Object.values(where));\n    }\n    return this.db.prepare(q).all(...v) as T[];\n  }\n\n  findById(id: string | number): T | null {\n    const stmt = this.db.prepare(\n      `SELECT * FROM ${this.esc(this.tableName)} WHERE ${this.esc(this.primaryKey)} = ?`\n    );\n    return (stmt.get(id) as T) || null;\n  }\n\n  findOne(where: Record<string, unknown>): T | null {\n    const conds = Object.keys(where).map(k => `${this.esc(k)} = ?`);\n    const stmt = this.db.prepare(\n      `SELECT * FROM ${this.esc(this.tableName)} WHERE ${conds.join(' AND ')} LIMIT 1`\n    );\n    return (stmt.get(...Object.values(where)) as T) || null;\n  }\n\n  update(id: string | number, data: Partial<T>): T | null {\n    const keys = Object.keys(data);\n    if (!keys.length) return this.findById(id);\n    const set = keys.map(k => `${this.esc(k)} = ?`).join(', ');\n    const stmt = this.db.prepare(\n      `UPDATE ${this.esc(this.tableName)} SET ${set} WHERE ${this.esc(this.primaryKey)} = ? RETURNING *`\n    );\n    return (stmt.get(...Object.values(data), id) as T) || null;\n  }\n\n  delete(id: string | number): boolean {\n    const stmt = this.db.prepare(\n      `DELETE FROM ${this.esc(this.tableName)} WHERE ${this.esc(this.primaryKey)} = ?`\n    );\n    const info = stmt.run(id);\n    return info.changes > 0;\n  }\n\n  softDelete(id: string | number): T | null {\n    const stmt = this.db.prepare(\n      `UPDATE ${this.esc(this.tableName)} SET deleted_at = datetime('now') WHERE ${this.esc(this.primaryKey)} = ? RETURNING *`\n    );\n    return (stmt.get(id) as T) || null;\n  }\n\n  bulkCreate(data: Partial<T>[]): T[] {\n    if (!data.length) return [];\n    const keys = Object.keys(data[0]);\n    const cols = keys.map(k => this.esc(k)).join(', ');\n    const ph = keys.map(() => '?').join(', ');\n    const insert = this.db.prepare(\n      `INSERT INTO ${this.esc(this.tableName)} (${cols}) VALUES (${ph}) RETURNING *`\n    );\n    const insertMany = this.db.transaction((items: Partial<T>[]) => {\n      return items.map(item => insert.get(...keys.map(k => (item as any)[k])) as T);\n    });\n    return insertMany(data);\n  }\n\n  bulkUpdate(ids: (string | number)[], data: Partial<T>): number {\n    if (!ids.length) return 0;\n    const keys = Object.keys(data);\n    const set = keys.map(k => `${this.esc(k)} = ?`).join(', ');\n    const ph = ids.map(() => '?').join(', ');\n    const stmt = this.db.prepare(\n      `UPDATE ${this.esc(this.tableName)} SET ${set} WHERE ${this.esc(this.primaryKey)} IN (${ph})`\n    );\n    const info = stmt.run(...Object.values(data), ...ids);\n    return info.changes;\n  }\n\n  paginate(opts: PaginationOptions = {}): PaginatedResult<T> {\n    const { page = 1, limit = 10, cursor, cursorField = this.primaryKey, orderBy = this.primaryKey, orderDir = 'DESC', where = {} } = opts;\n    \n    const countStmt = this.db.prepare(`SELECT COUNT(*) as count FROM ${this.esc(this.tableName)}`);\n    const total = (countStmt.get() as any).count as number;\n\n    const params: unknown[] = [];\n    let q = `SELECT * FROM ${this.esc(this.tableName)}`;\n    const conds: string[] = [];\n\n    if (Object.keys(where).length) {\n      conds.push(...Object.keys(where).map(k => `${this.esc(k)} = ?`));\n      params.push(...Object.values(where));\n    }\n    if (cursor) {\n      conds.push(`${this.esc(cursorField)} ${orderDir === 'ASC' ? '>' : '<'} ?`);\n      params.push(cursor);\n    }\n    if (conds.length) q += ` WHERE ${conds.join(' AND ')}`;\n    q += ` ORDER BY ${this.esc(orderBy)} ${orderDir} LIMIT ?`;\n    params.push(limit);\n    if (!cursor) { q += ` OFFSET ?`; params.push((page - 1) * limit); }\n\n    const data = this.db.prepare(q).all(...params) as T[];\n    const totalPages = Math.ceil(total / limit);\n\n    return {\n      data,\n      pagination: { total, page, limit, totalPages, hasNext: data.length === limit, hasPrev: page > 1, nextCursor: data.length ? (data[data.length - 1] as any)[cursorField] : undefined }\n    };\n  }\n\n  transaction<R>(fn: () => R): R {\n    return this.db.transaction(fn)();\n  }\n\n  count(where?: Record<string, unknown>): number {\n    let q = `SELECT COUNT(*) as count FROM ${this.esc(this.tableName)}`;\n    const v: unknown[] = [];\n    if (where && Object.keys(where).length) {\n      const conds = Object.keys(where).map(k => `${this.esc(k)} = ?`);\n      q += ` WHERE ${conds.join(' AND ')}`;\n      v.push(...Object.values(where));\n    }\n    return (this.db.prepare(q).get(...v) as any).count as number;\n  }\n}\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "queries",
    "type": "snippet"
  },
  {
    "name": "aws-s3-upload",
    "description": "AWS S3 file upload with presigned PUT URLs and POST policies for direct browser uploads",
    "dependencies": [
      "@aws-sdk/client-s3",
      "@aws-sdk/s3-request-presigner"
    ],
    "files": [
      {
        "name": "libs/uploads/aws-s3.ts",
        "path": "libs/uploads/aws-s3.ts",
        "content": "import {\n  S3Client,\n  PutObjectCommand,\n  GetObjectCommand,\n  DeleteObjectCommand,\n  HeadObjectCommand,\n} from '@aws-sdk/client-s3';\nimport { getSignedUrl } from '@aws-sdk/s3-request-presigner';\nimport { createHash, randomBytes } from 'crypto';\n\n/**\n * S3 client configuration\n */\nconst s3Client = new S3Client({\n  region: process.env.AWS_REGION || 'us-east-1',\n  credentials: process.env.AWS_ACCESS_KEY_ID\n    ? {\n        accessKeyId: process.env.AWS_ACCESS_KEY_ID,\n        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || '',\n      }\n    : undefined, // Use IAM role if no credentials provided\n});\n\nconst BUCKET = process.env.S3_BUCKET || '';\n\n/**\n * Generate a unique file key with date-based organization\n */\nconst generateKey = (filename: string, folder = 'uploads'): string => {\n  const ext = filename.split('.').pop() || '';\n  const uniqueId = randomBytes(8).toString('hex');\n  const date = new Date().toISOString().split('T')[0];\n  return `${folder}/${date}/${uniqueId}.${ext}`;\n};\n\n/**\n * Generate a presigned PUT URL for direct browser upload\n * Client uploads file directly to S3 using PUT request\n * \n * @example\n * // Server: Generate URL\n * const { uploadUrl, key } = await getPresignedPutUrl('image.png', 'image/png');\n * \n * // Client: Upload file\n * await fetch(uploadUrl, { method: 'PUT', body: file, headers: { 'Content-Type': 'image/png' } });\n */\nexport const getPresignedPutUrl = async (\n  filename: string,\n  contentType: string,\n  options: {\n    expiresIn?: number; // seconds, default: 5 minutes\n    folder?: string;\n    maxSize?: number; // bytes\n  } = {}\n): Promise<{ uploadUrl: string; key: string; publicUrl: string }> => {\n  const { expiresIn = 300, folder = 'uploads' } = options;\n  const key = generateKey(filename, folder);\n\n  const command = new PutObjectCommand({\n    Bucket: BUCKET,\n    Key: key,\n    ContentType: contentType,\n  });\n\n  const uploadUrl = await getSignedUrl(s3Client, command, { expiresIn });\n  const publicUrl = `https://${BUCKET}.s3.amazonaws.com/${key}`;\n\n  return { uploadUrl, key, publicUrl };\n};\n\n/**\n * Generate a presigned POST policy for form-based uploads\n * Allows setting conditions like max file size, content type restrictions\n * \n * @example\n * // Server: Generate policy\n * const policy = await getPresignedPostPolicy('image.png', 'image/', { maxSize: 5 * 1024 * 1024 });\n * \n * // Client: Upload using FormData\n * const formData = new FormData();\n * Object.entries(policy.fields).forEach(([k, v]) => formData.append(k, v));\n * formData.append('file', file);\n * await fetch(policy.url, { method: 'POST', body: formData });\n */\nexport const getPresignedPostPolicy = async (\n  filename: string,\n  contentTypePrefix: string, // e.g., 'image/' to allow any image\n  options: {\n    expiresIn?: number; // seconds, default: 5 minutes\n    folder?: string;\n    maxSize?: number; // bytes, default: 10MB\n  } = {}\n): Promise<{\n  url: string;\n  fields: Record<string, string>;\n  key: string;\n  publicUrl: string;\n}> => {\n  const { createPresignedPost } = await import('@aws-sdk/s3-presigned-post');\n  const { expiresIn = 300, folder = 'uploads', maxSize = 10 * 1024 * 1024 } = options;\n  const key = generateKey(filename, folder);\n\n  const { url, fields } = await createPresignedPost(s3Client, {\n    Bucket: BUCKET,\n    Key: key,\n    Conditions: [\n      ['content-length-range', 0, maxSize],\n      ['starts-with', '$Content-Type', contentTypePrefix],\n    ],\n    Expires: expiresIn,\n  });\n\n  const publicUrl = `https://${BUCKET}.s3.amazonaws.com/${key}`;\n\n  return { url, fields, key, publicUrl };\n};\n\n/**\n * Generate a presigned download URL for private files\n */\nexport const getPresignedDownloadUrl = async (\n  key: string,\n  expiresIn = 3600 // 1 hour default\n): Promise<string> => {\n  const command = new GetObjectCommand({\n    Bucket: BUCKET,\n    Key: key,\n  });\n\n  return getSignedUrl(s3Client, command, { expiresIn });\n};\n\n/**\n * Delete a file from S3\n */\nexport const deleteFile = async (key: string): Promise<void> => {\n  await s3Client.send(\n    new DeleteObjectCommand({\n      Bucket: BUCKET,\n      Key: key,\n    })\n  );\n};\n\n/**\n * Check if a file exists in S3\n */\nexport const fileExists = async (key: string): Promise<boolean> => {\n  try {\n    await s3Client.send(\n      new HeadObjectCommand({\n        Bucket: BUCKET,\n        Key: key,\n      })\n    );\n    return true;\n  } catch {\n    return false;\n  }\n};\n\n/**\n * Get file metadata from S3\n */\nexport const getFileMetadata = async (key: string) => {\n  const response = await s3Client.send(\n    new HeadObjectCommand({\n      Bucket: BUCKET,\n      Key: key,\n    })\n  );\n\n  return {\n    contentType: response.ContentType,\n    contentLength: response.ContentLength,\n    lastModified: response.LastModified,\n    etag: response.ETag,\n  };\n};\n\n/**\n * Upload a file buffer directly (server-side upload)\n */\nexport const uploadFile = async (\n  buffer: Buffer,\n  filename: string,\n  contentType: string,\n  folder = 'uploads'\n): Promise<{ key: string; url: string }> => {\n  const key = generateKey(filename, folder);\n\n  await s3Client.send(\n    new PutObjectCommand({\n      Bucket: BUCKET,\n      Key: key,\n      Body: buffer,\n      ContentType: contentType,\n    })\n  );\n\n  const url = `https://${BUCKET}.s3.amazonaws.com/${key}`;\n  return { key, url };\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "uploads",
    "type": "snippet"
  },
  {
    "name": "azure-blob-upload",
    "description": "Azure Blob Storage file upload with SAS URL generation",
    "dependencies": [
      "@azure/storage-blob"
    ],
    "files": [
      {
        "name": "libs/uploads/azure-blob.ts",
        "path": "libs/uploads/azure-blob.ts",
        "content": "import {\n  BlobServiceClient,\n  StorageSharedKeyCredential,\n  generateBlobSASQueryParameters,\n  BlobSASPermissions,\n  SASProtocol,\n} from '@azure/storage-blob';\n\n/**\n * Azure Blob Storage configuration\n */\nconst accountName = process.env.AZURE_STORAGE_ACCOUNT || '';\nconst accountKey = process.env.AZURE_STORAGE_KEY || '';\nconst containerName = process.env.AZURE_STORAGE_CONTAINER || '';\n\nconst sharedKeyCredential = new StorageSharedKeyCredential(accountName, accountKey);\nconst blobServiceClient = new BlobServiceClient(\n  `https://${accountName}.blob.core.windows.net`,\n  sharedKeyCredential\n);\nconst containerClient = blobServiceClient.getContainerClient(containerName);\n\n/**\n * Generate a unique blob name with date-based organization\n */\nconst generateBlobName = (filename: string, folder = 'uploads'): string => {\n  const ext = filename.split('.').pop() || '';\n  const uniqueId = Date.now().toString(36) + Math.random().toString(36).slice(2, 10);\n  const date = new Date().toISOString().split('T')[0];\n  return `${folder}/${date}/${uniqueId}.${ext}`;\n};\n\n/**\n * Generate a SAS URL for direct upload\n * \n * @example\n * // Server: Generate SAS URL\n * const { uploadUrl, blobName } = await getSasUploadUrl('image.png', 'image/png');\n * \n * // Client: Upload file with PUT request\n * await fetch(uploadUrl, { \n *   method: 'PUT', \n *   body: file, \n *   headers: { \n *     'x-ms-blob-type': 'BlockBlob',\n *     'Content-Type': 'image/png' \n *   } \n * });\n */\nexport const getSasUploadUrl = async (\n  filename: string,\n  contentType: string,\n  options: {\n    expiresIn?: number; // minutes, default: 15\n    folder?: string;\n  } = {}\n): Promise<{ uploadUrl: string; blobName: string; publicUrl: string }> => {\n  const { expiresIn = 15, folder = 'uploads' } = options;\n  const blobName = generateBlobName(filename, folder);\n\n  const startsOn = new Date();\n  const expiresOn = new Date(startsOn.getTime() + expiresIn * 60 * 1000);\n\n  const sasToken = generateBlobSASQueryParameters(\n    {\n      containerName,\n      blobName,\n      permissions: BlobSASPermissions.parse('cw'), // create, write\n      startsOn,\n      expiresOn,\n      contentType,\n      protocol: SASProtocol.Https,\n    },\n    sharedKeyCredential\n  ).toString();\n\n  const blobUrl = `https://${accountName}.blob.core.windows.net/${containerName}/${blobName}`;\n  const uploadUrl = `${blobUrl}?${sasToken}`;\n\n  return { uploadUrl, blobName, publicUrl: blobUrl };\n};\n\n/**\n * Generate a SAS URL for download/read access\n */\nexport const getSasDownloadUrl = async (\n  blobName: string,\n  expiresIn = 60 // minutes\n): Promise<string> => {\n  const startsOn = new Date();\n  const expiresOn = new Date(startsOn.getTime() + expiresIn * 60 * 1000);\n\n  const sasToken = generateBlobSASQueryParameters(\n    {\n      containerName,\n      blobName,\n      permissions: BlobSASPermissions.parse('r'), // read only\n      startsOn,\n      expiresOn,\n      protocol: SASProtocol.Https,\n    },\n    sharedKeyCredential\n  ).toString();\n\n  return `https://${accountName}.blob.core.windows.net/${containerName}/${blobName}?${sasToken}`;\n};\n\n/**\n * Delete a blob\n */\nexport const deleteFile = async (blobName: string): Promise<void> => {\n  const blobClient = containerClient.getBlobClient(blobName);\n  await blobClient.delete();\n};\n\n/**\n * Check if a blob exists\n */\nexport const fileExists = async (blobName: string): Promise<boolean> => {\n  const blobClient = containerClient.getBlobClient(blobName);\n  return blobClient.exists();\n};\n\n/**\n * Get blob properties/metadata\n */\nexport const getFileMetadata = async (blobName: string) => {\n  const blobClient = containerClient.getBlobClient(blobName);\n  const properties = await blobClient.getProperties();\n\n  return {\n    contentType: properties.contentType,\n    contentLength: properties.contentLength,\n    lastModified: properties.lastModified,\n    etag: properties.etag,\n    metadata: properties.metadata,\n  };\n};\n\n/**\n * Upload a file buffer directly (server-side upload)\n */\nexport const uploadFile = async (\n  buffer: Buffer,\n  filename: string,\n  contentType: string,\n  folder = 'uploads'\n): Promise<{ blobName: string; url: string }> => {\n  const blobName = generateBlobName(filename, folder);\n  const blockBlobClient = containerClient.getBlockBlobClient(blobName);\n\n  await blockBlobClient.upload(buffer, buffer.length, {\n    blobHTTPHeaders: { blobContentType: contentType },\n  });\n\n  const url = `https://${accountName}.blob.core.windows.net/${containerName}/${blobName}`;\n  return { blobName, url };\n};\n\n/**\n * Set blob access tier (Hot, Cool, Archive)\n */\nexport const setAccessTier = async (\n  blobName: string,\n  tier: 'Hot' | 'Cool' | 'Archive'\n): Promise<void> => {\n  const blobClient = containerClient.getBlobClient(blobName);\n  await blobClient.setAccessTier(tier);\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "uploads",
    "type": "snippet"
  },
  {
    "name": "cloudflare-r2-upload",
    "description": "Cloudflare R2 file upload with presigned URLs (S3-compatible API)",
    "dependencies": [
      "@aws-sdk/client-s3",
      "@aws-sdk/s3-request-presigner"
    ],
    "files": [
      {
        "name": "libs/uploads/cloudflare-r2.ts",
        "path": "libs/uploads/cloudflare-r2.ts",
        "content": "import {\n  S3Client,\n  PutObjectCommand,\n  GetObjectCommand,\n  DeleteObjectCommand,\n  HeadObjectCommand,\n} from '@aws-sdk/client-s3';\nimport { getSignedUrl } from '@aws-sdk/s3-request-presigner';\nimport { randomBytes } from 'crypto';\n\n/**\n * Cloudflare R2 client configuration\n * R2 uses S3-compatible API\n * \n * Required env vars:\n * - R2_ACCOUNT_ID: Cloudflare account ID\n * - R2_ACCESS_KEY_ID: R2 access key\n * - R2_SECRET_ACCESS_KEY: R2 secret key\n * - R2_BUCKET: Bucket name\n * - R2_PUBLIC_URL: (Optional) Custom domain or R2.dev URL for public access\n */\nconst r2Client = new S3Client({\n  region: 'auto', // R2 uses 'auto' region\n  endpoint: `https://${process.env.R2_ACCOUNT_ID}.r2.cloudflarestorage.com`,\n  credentials: {\n    accessKeyId: process.env.R2_ACCESS_KEY_ID || '',\n    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY || '',\n  },\n});\n\nconst BUCKET = process.env.R2_BUCKET || '';\nconst PUBLIC_URL = process.env.R2_PUBLIC_URL || ''; // e.g., https://files.example.com\n\n/**\n * Generate a unique file key with date-based organization\n */\nconst generateKey = (filename: string, folder = 'uploads'): string => {\n  const ext = filename.split('.').pop() || '';\n  const uniqueId = randomBytes(8).toString('hex');\n  const date = new Date().toISOString().split('T')[0];\n  return `${folder}/${date}/${uniqueId}.${ext}`;\n};\n\n/**\n * Generate a presigned PUT URL for direct upload\n * \n * @example\n * // Server: Generate URL\n * const { uploadUrl, key } = await getPresignedUploadUrl('image.png', 'image/png');\n * \n * // Client: Upload file\n * await fetch(uploadUrl, { method: 'PUT', body: file, headers: { 'Content-Type': 'image/png' } });\n */\nexport const getPresignedUploadUrl = async (\n  filename: string,\n  contentType: string,\n  options: {\n    expiresIn?: number; // seconds, default: 5 minutes\n    folder?: string;\n  } = {}\n): Promise<{ uploadUrl: string; key: string; publicUrl: string }> => {\n  const { expiresIn = 300, folder = 'uploads' } = options;\n  const key = generateKey(filename, folder);\n\n  const command = new PutObjectCommand({\n    Bucket: BUCKET,\n    Key: key,\n    ContentType: contentType,\n  });\n\n  const uploadUrl = await getSignedUrl(r2Client, command, { expiresIn });\n  const publicUrl = PUBLIC_URL ? `${PUBLIC_URL}/${key}` : '';\n\n  return { uploadUrl, key, publicUrl };\n};\n\n/**\n * Generate a presigned POST policy for form-based uploads\n * Allows setting conditions like max file size\n */\nexport const getPresignedPostPolicy = async (\n  filename: string,\n  contentTypePrefix: string,\n  options: {\n    expiresIn?: number; // seconds, default: 5 minutes\n    folder?: string;\n    maxSize?: number; // bytes, default: 10MB\n  } = {}\n): Promise<{\n  url: string;\n  fields: Record<string, string>;\n  key: string;\n  publicUrl: string;\n}> => {\n  const { createPresignedPost } = await import('@aws-sdk/s3-presigned-post');\n  const { expiresIn = 300, folder = 'uploads', maxSize = 10 * 1024 * 1024 } = options;\n  const key = generateKey(filename, folder);\n\n  const { url, fields } = await createPresignedPost(r2Client, {\n    Bucket: BUCKET,\n    Key: key,\n    Conditions: [\n      ['content-length-range', 0, maxSize],\n      ['starts-with', '$Content-Type', contentTypePrefix],\n    ],\n    Expires: expiresIn,\n  });\n\n  const publicUrl = PUBLIC_URL ? `${PUBLIC_URL}/${key}` : '';\n\n  return { url, fields, key, publicUrl };\n};\n\n/**\n * Generate a presigned download URL\n */\nexport const getPresignedDownloadUrl = async (\n  key: string,\n  expiresIn = 3600 // 1 hour default\n): Promise<string> => {\n  const command = new GetObjectCommand({\n    Bucket: BUCKET,\n    Key: key,\n  });\n\n  return getSignedUrl(r2Client, command, { expiresIn });\n};\n\n/**\n * Delete a file from R2\n */\nexport const deleteFile = async (key: string): Promise<void> => {\n  await r2Client.send(\n    new DeleteObjectCommand({\n      Bucket: BUCKET,\n      Key: key,\n    })\n  );\n};\n\n/**\n * Check if a file exists\n */\nexport const fileExists = async (key: string): Promise<boolean> => {\n  try {\n    await r2Client.send(\n      new HeadObjectCommand({\n        Bucket: BUCKET,\n        Key: key,\n      })\n    );\n    return true;\n  } catch {\n    return false;\n  }\n};\n\n/**\n * Get file metadata\n */\nexport const getFileMetadata = async (key: string) => {\n  const response = await r2Client.send(\n    new HeadObjectCommand({\n      Bucket: BUCKET,\n      Key: key,\n    })\n  );\n\n  return {\n    contentType: response.ContentType,\n    contentLength: response.ContentLength,\n    lastModified: response.LastModified,\n    etag: response.ETag,\n  };\n};\n\n/**\n * Upload a file buffer directly (server-side upload)\n */\nexport const uploadFile = async (\n  buffer: Buffer,\n  filename: string,\n  contentType: string,\n  folder = 'uploads'\n): Promise<{ key: string; url: string }> => {\n  const key = generateKey(filename, folder);\n\n  await r2Client.send(\n    new PutObjectCommand({\n      Bucket: BUCKET,\n      Key: key,\n      Body: buffer,\n      ContentType: contentType,\n    })\n  );\n\n  const url = PUBLIC_URL ? `${PUBLIC_URL}/${key}` : key;\n  return { key, url };\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "uploads",
    "type": "snippet"
  },
  {
    "name": "cloudinary-upload",
    "description": "Cloudinary file upload with signed upload parameters for direct browser uploads",
    "dependencies": [
      "cloudinary"
    ],
    "files": [
      {
        "name": "libs/uploads/cloudinary.ts",
        "path": "libs/uploads/cloudinary.ts",
        "content": "import { v2 as cloudinary, UploadApiOptions, UploadApiResponse } from 'cloudinary';\n\n/**\n * Cloudinary configuration\n */\ncloudinary.config({\n  cloud_name: process.env.CLOUDINARY_CLOUD_NAME || '',\n  api_key: process.env.CLOUDINARY_API_KEY || '',\n  api_secret: process.env.CLOUDINARY_API_SECRET || '',\n  secure: true,\n});\n\n/**\n * Generate signed upload parameters for direct browser upload\n * Uses Cloudinary's signature-based authentication\n * \n * @example\n * // Server: Generate signed params\n * const params = getSignedUploadParams({ folder: 'avatars', maxFileSize: 5 * 1024 * 1024 });\n * \n * // Client: Upload using fetch with FormData\n * const formData = new FormData();\n * formData.append('file', file);\n * formData.append('api_key', params.apiKey);\n * formData.append('timestamp', params.timestamp.toString());\n * formData.append('signature', params.signature);\n * formData.append('folder', params.folder);\n * await fetch(params.uploadUrl, { method: 'POST', body: formData });\n */\nexport const getSignedUploadParams = (\n  options: {\n    folder?: string;\n    resourceType?: 'image' | 'video' | 'raw' | 'auto';\n    allowedFormats?: string[]; // e.g., ['jpg', 'png', 'webp']\n    maxFileSize?: number; // bytes\n    transformation?: string; // e.g., 'w_500,h_500,c_limit'\n    eager?: string; // Eager transformations\n    tags?: string[];\n    context?: Record<string, string>;\n  } = {}\n): {\n  uploadUrl: string;\n  apiKey: string;\n  timestamp: number;\n  signature: string;\n  folder: string;\n  cloudName: string;\n} => {\n  const {\n    folder = 'uploads',\n    resourceType = 'auto',\n    allowedFormats,\n    transformation,\n    eager,\n    tags,\n    context,\n  } = options;\n\n  const timestamp = Math.round(Date.now() / 1000);\n\n  // Build params object for signature\n  const params: Record<string, string | number> = {\n    timestamp,\n    folder,\n  };\n\n  if (allowedFormats) params.allowed_formats = allowedFormats.join(',');\n  if (transformation) params.transformation = transformation;\n  if (eager) params.eager = eager;\n  if (tags) params.tags = tags.join(',');\n  if (context) params.context = Object.entries(context).map(([k, v]) => `${k}=${v}`).join('|');\n\n  const signature = cloudinary.utils.api_sign_request(\n    params,\n    process.env.CLOUDINARY_API_SECRET || ''\n  );\n\n  return {\n    uploadUrl: `https://api.cloudinary.com/v1_1/${process.env.CLOUDINARY_CLOUD_NAME}/${resourceType}/upload`,\n    apiKey: process.env.CLOUDINARY_API_KEY || '',\n    timestamp,\n    signature,\n    folder,\n    cloudName: process.env.CLOUDINARY_CLOUD_NAME || '',\n  };\n};\n\n/**\n * Generate a signed upload URL (unsigned uploads must be enabled in Cloudinary settings)\n * For direct URL-based uploads without form data\n */\nexport const getSignedUploadUrl = (\n  options: {\n    folder?: string;\n    publicId?: string;\n    resourceType?: 'image' | 'video' | 'raw' | 'auto';\n    expiresAt?: number; // Unix timestamp\n  } = {}\n): string => {\n  const { folder = 'uploads', publicId, resourceType = 'auto', expiresAt } = options;\n\n  const timestamp = Math.round(Date.now() / 1000);\n  const expires = expiresAt || timestamp + 3600; // 1 hour default\n\n  const params: Record<string, string | number> = {\n    timestamp,\n    folder,\n  };\n\n  if (publicId) params.public_id = publicId;\n\n  const signature = cloudinary.utils.api_sign_request(\n    { ...params, expires_at: expires },\n    process.env.CLOUDINARY_API_SECRET || ''\n  );\n\n  const queryParams = new URLSearchParams({\n    api_key: process.env.CLOUDINARY_API_KEY || '',\n    timestamp: timestamp.toString(),\n    signature,\n    folder,\n    ...(publicId && { public_id: publicId }),\n  });\n\n  return `https://api.cloudinary.com/v1_1/${process.env.CLOUDINARY_CLOUD_NAME}/${resourceType}/upload?${queryParams}`;\n};\n\n/**\n * Upload a file from a URL (server-side)\n */\nexport const uploadFromUrl = async (\n  url: string,\n  options: UploadApiOptions = {}\n): Promise<UploadApiResponse> => {\n  return cloudinary.uploader.upload(url, {\n    folder: 'uploads',\n    resource_type: 'auto',\n    ...options,\n  });\n};\n\n/**\n * Upload a buffer (server-side)\n */\nexport const uploadBuffer = async (\n  buffer: Buffer,\n  options: UploadApiOptions = {}\n): Promise<UploadApiResponse> => {\n  return new Promise((resolve, reject) => {\n    const uploadStream = cloudinary.uploader.upload_stream(\n      {\n        folder: 'uploads',\n        resource_type: 'auto',\n        ...options,\n      },\n      (error, result) => {\n        if (error) reject(error);\n        else if (result) resolve(result);\n        else reject(new Error('Upload failed'));\n      }\n    );\n\n    uploadStream.end(buffer);\n  });\n};\n\n/**\n * Delete a file by public_id\n */\nexport const deleteFile = async (\n  publicId: string,\n  resourceType: 'image' | 'video' | 'raw' = 'image'\n): Promise<{ result: string }> => {\n  return cloudinary.uploader.destroy(publicId, { resource_type: resourceType });\n};\n\n/**\n * Generate a transformation URL\n * \n * @example\n * getTransformUrl('folder/image123', { width: 300, height: 300, crop: 'fill' })\n * // Returns: https://res.cloudinary.com/cloud/image/upload/w_300,h_300,c_fill/folder/image123\n */\nexport const getTransformUrl = (\n  publicId: string,\n  transformations: {\n    width?: number;\n    height?: number;\n    crop?: 'fill' | 'fit' | 'scale' | 'thumb' | 'crop' | 'limit';\n    quality?: number | 'auto';\n    format?: 'auto' | 'webp' | 'jpg' | 'png' | 'avif';\n    blur?: number;\n    grayscale?: boolean;\n  }\n): string => {\n  const { width, height, crop, quality, format, blur, grayscale } = transformations;\n\n  return cloudinary.url(publicId, {\n    transformation: [\n      {\n        ...(width && { width }),\n        ...(height && { height }),\n        ...(crop && { crop }),\n        ...(quality && { quality }),\n        ...(format && { fetch_format: format }),\n        ...(blur && { effect: `blur:${blur}` }),\n        ...(grayscale && { effect: 'grayscale' }),\n      },\n    ],\n  });\n};\n\n/**\n * Get optimized delivery URL with automatic format and quality\n */\nexport const getOptimizedUrl = (publicId: string, options: { width?: number; height?: number } = {}): string => {\n  return cloudinary.url(publicId, {\n    transformation: [\n      {\n        fetch_format: 'auto',\n        quality: 'auto',\n        ...(options.width && { width: options.width }),\n        ...(options.height && { height: options.height }),\n      },\n    ],\n  });\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "uploads",
    "type": "snippet"
  },
  {
    "name": "gcp-storage-upload",
    "description": "Google Cloud Storage file upload with signed URLs and resumable uploads",
    "dependencies": [
      "@google-cloud/storage"
    ],
    "files": [
      {
        "name": "libs/uploads/gcp-storage.ts",
        "path": "libs/uploads/gcp-storage.ts",
        "content": "import { Storage, GetSignedUrlConfig } from '@google-cloud/storage';\n\n/**\n * GCS client configuration\n * \n * Authentication options:\n * 1. Set GOOGLE_APPLICATION_CREDENTIALS env var to path of service account JSON\n * 2. Pass keyFilename in Storage constructor\n * 3. Use default credentials (GCE, Cloud Run, etc.)\n */\nconst storage = new Storage({\n  projectId: process.env.GCP_PROJECT_ID,\n  // keyFilename: process.env.GCP_KEY_FILE, // Optional: path to service account JSON\n});\n\nconst BUCKET_NAME = process.env.GCS_BUCKET || '';\nconst bucket = storage.bucket(BUCKET_NAME);\n\n/**\n * Generate a unique file path with date-based organization\n */\nconst generatePath = (filename: string, folder = 'uploads'): string => {\n  const ext = filename.split('.').pop() || '';\n  const uniqueId = Date.now().toString(36) + Math.random().toString(36).slice(2, 10);\n  const date = new Date().toISOString().split('T')[0];\n  return `${folder}/${date}/${uniqueId}.${ext}`;\n};\n\n/**\n * Generate a signed URL for direct PUT upload\n * Uses V4 signing (recommended)\n * \n * @example\n * // Server: Generate URL\n * const { uploadUrl, path } = await getSignedUploadUrl('image.png', 'image/png');\n * \n * // Client: Upload file\n * await fetch(uploadUrl, { method: 'PUT', body: file, headers: { 'Content-Type': 'image/png' } });\n */\nexport const getSignedUploadUrl = async (\n  filename: string,\n  contentType: string,\n  options: {\n    expiresIn?: number; // minutes, default: 15\n    folder?: string;\n  } = {}\n): Promise<{ uploadUrl: string; path: string; publicUrl: string }> => {\n  const { expiresIn = 15, folder = 'uploads' } = options;\n  const path = generatePath(filename, folder);\n  const file = bucket.file(path);\n\n  const config: GetSignedUrlConfig = {\n    version: 'v4',\n    action: 'write',\n    expires: Date.now() + expiresIn * 60 * 1000,\n    contentType,\n  };\n\n  const [uploadUrl] = await file.getSignedUrl(config);\n  const publicUrl = `https://storage.googleapis.com/${BUCKET_NAME}/${path}`;\n\n  return { uploadUrl, path, publicUrl };\n};\n\n/**\n * Generate a resumable upload URL for large files\n * Supports chunked uploads and resume on failure\n * \n * @example\n * // Server: Generate resumable URL\n * const { uploadUrl, path } = await getResumableUploadUrl('video.mp4', 'video/mp4');\n * \n * // Client: Use resumable upload protocol\n * // First PUT to uploadUrl with Content-Length: 0 to get session URI\n * // Then PUT chunks to the session URI\n */\nexport const getResumableUploadUrl = async (\n  filename: string,\n  contentType: string,\n  options: {\n    folder?: string;\n    metadata?: Record<string, string>;\n  } = {}\n): Promise<{ uploadUrl: string; path: string; publicUrl: string }> => {\n  const { folder = 'uploads', metadata = {} } = options;\n  const path = generatePath(filename, folder);\n  const file = bucket.file(path);\n\n  const [uploadUrl] = await file.createResumableUpload({\n    metadata: {\n      contentType,\n      metadata,\n    },\n  });\n\n  const publicUrl = `https://storage.googleapis.com/${BUCKET_NAME}/${path}`;\n\n  return { uploadUrl, path, publicUrl };\n};\n\n/**\n * Generate a signed download URL for private files\n */\nexport const getSignedDownloadUrl = async (\n  path: string,\n  expiresIn = 60 // minutes\n): Promise<string> => {\n  const file = bucket.file(path);\n\n  const config: GetSignedUrlConfig = {\n    version: 'v4',\n    action: 'read',\n    expires: Date.now() + expiresIn * 60 * 1000,\n  };\n\n  const [url] = await file.getSignedUrl(config);\n  return url;\n};\n\n/**\n * Delete a file from GCS\n */\nexport const deleteFile = async (path: string): Promise<void> => {\n  await bucket.file(path).delete();\n};\n\n/**\n * Check if a file exists\n */\nexport const fileExists = async (path: string): Promise<boolean> => {\n  const [exists] = await bucket.file(path).exists();\n  return exists;\n};\n\n/**\n * Get file metadata\n */\nexport const getFileMetadata = async (path: string) => {\n  const [metadata] = await bucket.file(path).getMetadata();\n\n  return {\n    contentType: metadata.contentType,\n    size: metadata.size,\n    updated: metadata.updated,\n    md5Hash: metadata.md5Hash,\n    crc32c: metadata.crc32c,\n  };\n};\n\n/**\n * Upload a file buffer directly (server-side upload)\n */\nexport const uploadFile = async (\n  buffer: Buffer,\n  filename: string,\n  contentType: string,\n  folder = 'uploads'\n): Promise<{ path: string; url: string }> => {\n  const path = generatePath(filename, folder);\n  const file = bucket.file(path);\n\n  await file.save(buffer, {\n    contentType,\n    resumable: false,\n  });\n\n  const url = `https://storage.googleapis.com/${BUCKET_NAME}/${path}`;\n  return { path, url };\n};\n\n/**\n * Make a file publicly accessible\n */\nexport const makePublic = async (path: string): Promise<string> => {\n  await bucket.file(path).makePublic();\n  return `https://storage.googleapis.com/${BUCKET_NAME}/${path}`;\n};\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "uploads",
    "type": "snippet"
  },
  {
    "name": "shared-logger",
    "description": "Structured Pino logger configuration for any Node.js/Bun project",
    "dependencies": [
      "pino",
      "pino-pretty"
    ],
    "files": [
      {
        "name": "src/utils/logger.ts",
        "path": "src/utils/logger.ts",
        "content": "import pino from \"pino\";\n\nexport const logger = pino({\n  level: process.env.LOG_LEVEL || \"info\",\n  transport: process.env.NODE_ENV !== \"production\"\n    ? {\n        target: \"pino-pretty\",\n        options: {\n          colorize: true,\n          ignore: \"pid,hostname\",\n          translateTime: \"SYS:standard\",\n        },\n      }\n    : undefined,\n});\n\n/**\n * Example usage:\n * \n * logger.info({ user_id: 123 }, \"User logged in\");\n * logger.error(err, \"An unexpected error occurred\");\n */\n"
      }
    ],
    "version": "v1",
    "framework": "shared",
    "category": "utils",
    "type": "snippet"
  }
]
